{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš™ï¸ğŸ”¥ Estimativa de Temperatura Interna em Motores ElÃ©tricos via Physicsâ€‘Informed Neural Networks (PINNs)\n",
    "\n",
    "> **Trabalho Final â€“ Redes Neurais Artificiais e Deep Learning**  \n",
    "> **Autor:** Thales Ferreira â€¢ **ValidaÃ§Ã£o prÃ©via:** 09 / 06 â€¢ **Entrega final:** 16 / 06\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”® 1. IntroduÃ§Ã£o\n",
    "\n",
    "Este notebook implementa um modelo baseado em **Physicsâ€‘Informed Neural Networks (PINNs)** para estimar a temperatura interna de motores elÃ©tricos industriais usando apenas variÃ¡veis facilmente mensurÃ¡veis (corrente RMS e temperatura da carcaÃ§a).\n",
    "\n",
    "### 1.1 HipÃ³tese de Trabalho\n",
    "> Um PINN devidamente calibrado atingirÃ¡ **MAE â‰¤ 5 Â°C** na estimativa da temperatura interna em regime de produÃ§Ã£o contÃ­nua.\n",
    "\n",
    "### 1.2 Metodologia\n",
    "O PINN minimiza simultaneamente:\n",
    "- Erro nos dados disponÃ­veis\n",
    "- ResÃ­duo da **equaÃ§Ã£o de calor 1â€‘D** com fonte \\(I^2R\\)\n",
    "- CondiÃ§Ãµes de contorno\n",
    "\n",
    "### 1.3 Experimentos Planejados\n",
    "- **E1:** Verificar aprendizagem da PDE com dados sintÃ©ticos\n",
    "- **E2:** Ajustar parÃ¢metros fÃ­sicos (Î±, R) com dados reais\n",
    "- **E3:** InferÃªncia em dados inÃ©ditos para validaÃ§Ã£o\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 2. ConfiguraÃ§Ã£o do Ambiente\n",
    "\n",
    "Nesta seÃ§Ã£o, vamos instalar e importar as bibliotecas necessÃ¡rias para o desenvolvimento do PINN, incluindo fallback automÃ¡tico entre DeepXDE e SciANN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 InstalaÃ§Ã£o das dependÃªncias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstalaÃ§Ã£o automÃ¡tica das dependÃªncias PINN - VersÃ£o atualizada para Python 3.12\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"\n",
    "    Instala as dependÃªncias do projeto a partir do requirements.txt\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        bool: True se as dependÃªncias foram instaladas com sucesso, False caso contrÃ¡rio\n",
    "    \n",
    "    Raises:\n",
    "        Exception: Se ocorrer um erro inesperado ao instalar as dependÃªncias\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Primeiro tenta o caminho local (se executando de dentro da pasta pinn)\n",
    "    req_file = Path(\"requirements.txt\")\n",
    "    \n",
    "    # Se nÃ£o encontrar, tenta o caminho relativo a partir da raiz do projeto\n",
    "    if not req_file.exists():\n",
    "        req_file = Path(\"pinn/requirements.txt\")\n",
    "        if not req_file.exists():\n",
    "            print(\"âŒ Arquivo requirements.txt nÃ£o encontrado\")\n",
    "            print(f\"DiretÃ³rio atual: {os.getcwd()}\")\n",
    "            return False\n",
    "    \n",
    "    print(f\"ğŸ“ Usando requirements.txt: {req_file.absolute()}\")\n",
    "    \n",
    "    try:\n",
    "        # Usa o pip do ambiente atual\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \n",
    "            \"-m\", \n",
    "            \"pip\", \n",
    "            \"install\", \n",
    "            \"-r\", \n",
    "            str(req_file),\n",
    "            \"--upgrade\"  # Garante que usa versÃµes mais recentes compatÃ­veis\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… DependÃªncias instaladas com sucesso\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âš ï¸ Erro na instalaÃ§Ã£o automÃ¡tica (cÃ³digo {result.returncode})\")\n",
    "            print(\"Detalhes do erro:\")\n",
    "            print(result.stderr)\n",
    "            print(\"\\nPor favor, instale manualmente com:\")\n",
    "            print(f\"  {sys.executable} -m pip install -r {req_file}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro inesperado: {str(e)}\")\n",
    "        print(\"Por favor, instale manualmente com:\")\n",
    "        print(f\"  {sys.executable} -m pip install -r {req_file}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_package(package_name, version=None):\n",
    "    \"\"\"Instala um pacote especÃ­fico usando pip se nÃ£o estiver disponÃ­vel\"\"\"\n",
    "    try:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\"]\n",
    "        if version:\n",
    "            cmd.append(f\"{package_name}>={version}\")  # Usa >= para permitir versÃµes mais recentes\n",
    "        else:\n",
    "            cmd.append(package_name)\n",
    "        cmd.append(\"--upgrade\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… {package_name} instalado com sucesso\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âŒ Erro ao instalar {package_name} (cÃ³digo {result.returncode})\")\n",
    "            print(\"Detalhes do erro:\")\n",
    "            print(result.stderr[:500] + \"...\" if len(result.stderr) > 500 else result.stderr)\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro inesperado ao instalar {package_name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Verifica a versÃ£o do Python\n",
    "print(f\"ğŸ Python version: {sys.version}\")\n",
    "\n",
    "# Tenta instalar as dependÃªncias\n",
    "success = install_requirements()\n",
    "if not success:\n",
    "    print(\"\\nâš ï¸ Tentando instalar dependÃªncias crÃ­ticas individualmente...\")\n",
    "    # VersÃµes compatÃ­veis com Python 3.12\n",
    "    critical_packages = {\n",
    "        \"numpy\": \"1.24.0\",\n",
    "        \"tensorflow\": \"2.16.0\", \n",
    "        \"scipy\": \"1.11.1\",\n",
    "        \"sciann\": \"0.7.0\"\n",
    "    }\n",
    "    for pkg, ver in critical_packages.items():\n",
    "        install_package(pkg, ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ImportaÃ§Ã£o das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ TensorFlow Version: 2.19.0\n",
      "ğŸ² Semente definida: 96\n",
      "ğŸ“ DiretÃ³rio de experimentos: c:\\dev\\machine_learning\\pinn\\experiments\n",
      "âœ… Bibliotecas bÃ¡sicas importadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# ImportaÃ§Ã£o das bibliotecas bÃ¡sicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ConfiguraÃ§Ãµes gerais\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Setup determinÃ­stico para reprodutibilidade\n",
    "RANDOM_SEED = 96\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "tf.keras.utils.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"ğŸ”§ TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"ğŸ² Semente definida: {RANDOM_SEED}\")\n",
    "\n",
    "# Criar diretÃ³rios para experimentos\n",
    "experiment_dir = Path(\"experiments\")\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "print(f\"ğŸ“ DiretÃ³rio de experimentos: {experiment_dir.absolute()}\")\n",
    "\n",
    "print(\"âœ… Bibliotecas bÃ¡sicas importadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\dev\\machine_learning\\.venv\\Lib\\site-packages\\deepxde\\backend\\tensorflow_compat_v1\\tensor.py:25: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\dev\\machine_learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "âœ… DeepXDE 1.14.0 importado com sucesso\n",
      "ğŸš€ Backend PINN selecionado: DeepXDE\n",
      "Set the default float type to float32\n",
      "ğŸ”§ DeepXDE configurado para usar TensorFlow com float32\n"
     ]
    }
   ],
   "source": [
    "# DetecÃ§Ã£o e configuraÃ§Ã£o do backend PINN (DeepXDE vs SciANN)\n",
    "pinn_backend = None\n",
    "pinn_backend_name = \"Nenhum\"\n",
    "\n",
    "# Tentativa 1: DeepXDE\n",
    "try:\n",
    "    import deepxde as dde\n",
    "    pinn_backend = \"deepxde\"\n",
    "    pinn_backend_name = \"DeepXDE\"\n",
    "    print(f\"âœ… DeepXDE {dde.__version__} importado com sucesso\")\n",
    "except ImportError:\n",
    "    print(\"âŒ DeepXDE nÃ£o disponÃ­vel, tentando SciANN...\")\n",
    "    \n",
    "    # Tentativa 2: SciANN\n",
    "    try:\n",
    "        import sciann as sn\n",
    "        from sciann.models import Model\n",
    "        from sciann.constraints import Data\n",
    "        pinn_backend = \"sciann\"\n",
    "        pinn_backend_name = \"SciANN\"\n",
    "        print(f\"âœ… SciANN importado com sucesso\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ SciANN nÃ£o disponÃ­vel\")\n",
    "\n",
    "if pinn_backend is None:\n",
    "    print(\"âš ï¸ Nenhum backend PINN disponÃ­vel!\")\n",
    "    print(\"ğŸ“‹ InstruÃ§Ãµes de instalaÃ§Ã£o:\")\n",
    "    print(\"   DeepXDE: pip install deepxde\")\n",
    "    print(\"   SciANN:  pip install sciann\")\n",
    "    print(\"ğŸ”„ Implementando PINN manual com TensorFlow/Keras\")\n",
    "    pinn_backend = \"manual\"\n",
    "    pinn_backend_name = \"Manual (TensorFlow/Keras)\"\n",
    "\n",
    "print(f\"ğŸš€ Backend PINN selecionado: {pinn_backend_name}\")\n",
    "\n",
    "# ConfiguraÃ§Ãµes especÃ­ficas do backend\n",
    "if pinn_backend == \"deepxde\":\n",
    "    # Configurar DeepXDE para usar TensorFlow\n",
    "    dde.config.set_default_float(\"float32\")\n",
    "    print(\"ğŸ”§ DeepXDE configurado para usar TensorFlow com float32\")\n",
    "elif pinn_backend == \"sciann\":\n",
    "    # ConfiguraÃ§Ãµes do SciANN se necessÃ¡rio\n",
    "    print(\"ğŸ”§ SciANN pronto para uso\")\n",
    "else:\n",
    "    # ConfiguraÃ§Ãµes para implementaÃ§Ã£o manual\n",
    "    print(\"ğŸ”§ ImplementaÃ§Ã£o manual configurada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§® 3. ParÃ¢metros FÃ­sicos e ConfiguraÃ§Ãµes\n",
    "\n",
    "DefiniÃ§Ã£o dos parÃ¢metros fÃ­sicos do motor e configuraÃ§Ãµes dos experimentos conforme descrito no README.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ ConfiguraÃ§Ãµes carregadas:\n",
      "   ResistÃªncia: 2.3 Î©\n",
      "   Difusividade tÃ©rmica: 1.10e-04 mÂ²/s\n",
      "   Comprimento: 0.02 m\n",
      "   Arquitetura da rede: 6 Ã— 64\n",
      "   Backend PINN: DeepXDE\n"
     ]
    }
   ],
   "source": [
    "# ParÃ¢metros fÃ­sicos do motor\n",
    "PHYSICS_PARAMS = {\n",
    "    'R': 2.3,              # ResistÃªncia [Î©]\n",
    "    'alpha': 1.1e-4,       # Difusividade tÃ©rmica [mÂ²/s] \n",
    "    'L': 0.02,             # Comprimento [m]\n",
    "    'rho_cp': 3.8e6,       # Densidade Ã— calor especÃ­fico [J/(mÂ³Â·K)]\n",
    "    'k': 0.4               # Condutividade tÃ©rmica [W/(mÂ·K)] - calculada: k = Î± Ã— Ïcp\n",
    "}\n",
    "\n",
    "# ParÃ¢metros de ruÃ­do para geraÃ§Ã£o sintÃ©tica\n",
    "NOISE_PARAMS = {\n",
    "    'temp_noise_std': 0.5,    # Desvio padrÃ£o do ruÃ­do de temperatura [Â°C]\n",
    "    'current_noise_pct': 0.02  # Percentual de ruÃ­do na corrente [Â±2%]\n",
    "}\n",
    "\n",
    "# ConfiguraÃ§Ãµes dos experimentos\n",
    "EXPERIMENT_CONFIG = {\n",
    "    'epochs_quick': 100,      # Ã‰pocas para testes rÃ¡pidos\n",
    "    'epochs_full': 1000,      # Ã‰pocas para treinamento completo\n",
    "    'batch_size': 32,         # Tamanho do batch\n",
    "    'learning_rate': 1e-3,    # Taxa de aprendizado inicial\n",
    "    'patience': 50,           # PaciÃªncia para early stopping\n",
    "    'validation_split': 0.2,  # FraÃ§Ã£o para validaÃ§Ã£o\n",
    "    'test_split': 0.1         # FraÃ§Ã£o para teste\n",
    "}\n",
    "\n",
    "# ConfiguraÃ§Ãµes da rede neural\n",
    "NETWORK_CONFIG = {\n",
    "    'hidden_layers': 6,       # NÃºmero de camadas ocultas\n",
    "    'neurons_per_layer': 64,  # NeurÃ´nios por camada\n",
    "    'activation': 'tanh',     # FunÃ§Ã£o de ativaÃ§Ã£o\n",
    "    'output_activation': 'linear'  # AtivaÃ§Ã£o da saÃ­da\n",
    "}\n",
    "\n",
    "# ConfiguraÃ§Ãµes da funÃ§Ã£o de perda PINN\n",
    "LOSS_WEIGHTS = {\n",
    "    'lambda_data': 1.0,       # Peso da perda dos dados\n",
    "    'lambda_pde': 1.0,        # Peso da perda da PDE\n",
    "    'lambda_bc': 1.0          # Peso da perda das condiÃ§Ãµes de contorno\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ ConfiguraÃ§Ãµes carregadas:\")\n",
    "print(f\"   ResistÃªncia: {PHYSICS_PARAMS['R']} Î©\")\n",
    "print(f\"   Difusividade tÃ©rmica: {PHYSICS_PARAMS['alpha']:.2e} mÂ²/s\")\n",
    "print(f\"   Comprimento: {PHYSICS_PARAMS['L']} m\")\n",
    "print(f\"   Arquitetura da rede: {NETWORK_CONFIG['hidden_layers']} Ã— {NETWORK_CONFIG['neurons_per_layer']}\")\n",
    "print(f\"   Backend PINN: {pinn_backend_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 4. FunÃ§Ãµes UtilitÃ¡rias\n",
    "\n",
    "ImplementaÃ§Ã£o das funÃ§Ãµes auxiliares para mÃ©tricas, plotagem e manipulaÃ§Ã£o de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§¾ 4.1 MÃ©tricas de AvaliaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula mÃ©tricas de avaliaÃ§Ã£o para regressÃ£o.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): Valores reais\n",
    "        y_pred (array): Valores preditos\n",
    "        \n",
    "    Returns:\n",
    "        dict: DicionÃ¡rio com mÃ©tricas MAE, RMSE e correlaÃ§Ã£o de Pearson\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # CorrelaÃ§Ã£o de Pearson\n",
    "    if len(y_true) > 1:\n",
    "        pearson_r, pearson_p = pearsonr(y_true.flatten(), y_pred.flatten())\n",
    "    else:\n",
    "        pearson_r, pearson_p = 0.0, 1.0\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'Pearson_r': pearson_r,\n",
    "        'Pearson_p': pearson_p\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‰ 4.2 Plotando histÃ³rico de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07601108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, experiment_name, save_dir=None):\n",
    "    \"\"\"\n",
    "    Plota as curvas de aprendizado do treinamento.\n",
    "    \n",
    "    Args:\n",
    "        history: HistÃ³rico do treinamento\n",
    "        experiment_name (str): Nome do experimento\n",
    "        save_dir (Path): DiretÃ³rio para salvar o plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Curvas de Aprendizado - {experiment_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss total\n",
    "    axes[0, 0].plot(history.history['loss'], label='Treino', linewidth=2)\n",
    "    if 'val_loss' in history.history:\n",
    "        axes[0, 0].plot(history.history['val_loss'], label='ValidaÃ§Ã£o', linewidth=2)\n",
    "    axes[0, 0].set_title('Perda Total')\n",
    "    axes[0, 0].set_xlabel('Ã‰poca')\n",
    "    axes[0, 0].set_ylabel('Perda')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE (se disponÃ­vel)\n",
    "    if 'mae' in history.history:\n",
    "        axes[0, 1].plot(history.history['mae'], label='Treino MAE', linewidth=2)\n",
    "        if 'val_mae' in history.history:\n",
    "            axes[0, 1].plot(history.history['val_mae'], label='ValidaÃ§Ã£o MAE', linewidth=2)\n",
    "        axes[0, 1].set_title('Erro Absoluto MÃ©dio')\n",
    "        axes[0, 1].set_xlabel('Ã‰poca')\n",
    "        axes[0, 1].set_ylabel('MAE [Â°C]')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'MAE nÃ£o disponÃ­vel', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "        axes[0, 1].set_title('MAE nÃ£o registrado')\n",
    "    \n",
    "    # Learning rate (se disponÃ­vel)\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 0].plot(history.history['lr'], linewidth=2, color='orange')\n",
    "        axes[1, 0].set_title('Taxa de Aprendizado')\n",
    "        axes[1, 0].set_xlabel('Ã‰poca')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'LR nÃ£o disponÃ­vel', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        axes[1, 0].set_title('Learning Rate nÃ£o registrado')\n",
    "    \n",
    "    # Componentes da perda PINN (se disponÃ­vel)\n",
    "    loss_components = [key for key in history.history.keys() if 'loss' in key and key != 'loss' and 'val' not in key]\n",
    "    if loss_components:\n",
    "        for component in loss_components:\n",
    "            axes[1, 1].plot(history.history[component], label=component.replace('_', ' ').title(), linewidth=2)\n",
    "        axes[1, 1].set_title('Componentes da Perda PINN')\n",
    "        axes[1, 1].set_xlabel('Ã‰poca')\n",
    "        axes[1, 1].set_ylabel('Perda')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Componentes nÃ£o disponÃ­veis', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Componentes da Perda nÃ£o registrados')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        save_path = save_dir / f\"{experiment_name}_training_curves.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ“Š Curvas de aprendizado salvas em: {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ†š 4.3 PrediÃ§Ãµes vs. Dados Reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_vs_actual(y_true, y_pred, experiment_name, save_dir=None):\n",
    "    \"\"\"\n",
    "    Plota prediÃ§Ãµes vs valores reais com mÃ©tricas.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): Valores reais\n",
    "        y_pred (array): Valores preditos  \n",
    "        experiment_name (str): Nome do experimento\n",
    "        save_dir (Path): DiretÃ³rio para salvar o plot\n",
    "    \"\"\"\n",
    "    metrics = calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6, s=20)\n",
    "    \n",
    "    # Linha diagonal perfeita\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='PrediÃ§Ã£o Perfeita')\n",
    "    \n",
    "    plt.xlabel('Temperatura Real [Â°C]')\n",
    "    plt.ylabel('Temperatura Predita [Â°C]')\n",
    "    plt.title(f'{experiment_name} - PrediÃ§Ãµes vs Real')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adicionar mÃ©tricas no plot\n",
    "    textstr = f'MAE: {metrics[\"MAE\"]:.2f}Â°C\\nRMSE: {metrics[\"RMSE\"]:.2f}Â°C\\nPearson r: {metrics[\"Pearson_r\"]:.3f}'\n",
    "    plt.gca().text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    # Histograma dos resÃ­duos\n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = y_true - y_pred\n",
    "    plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('ResÃ­duos [Â°C]')\n",
    "    plt.ylabel('FrequÃªncia')\n",
    "    plt.title('DistribuiÃ§Ã£o dos ResÃ­duos')\n",
    "    plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # EstatÃ­sticas dos resÃ­duos\n",
    "    mean_residual = np.mean(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "    textstr_res = f'MÃ©dia: {mean_residual:.3f}Â°C\\nDesvio: {std_residual:.3f}Â°C'\n",
    "    plt.gca().text(0.95, 0.95, textstr_res, transform=plt.gca().transAxes, fontsize=10,\n",
    "                   horizontalalignment='right', verticalalignment='top', \n",
    "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        save_path = save_dir / f\"{experiment_name}_predictions.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ“Š Plot de prediÃ§Ãµes salvo em: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¾ 4.4 Salvar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_results(experiment_name, model, history, metrics, config, save_dir):\n",
    "    \"\"\"\n",
    "    Salva os resultados de um experimento em disco.\n",
    "    \n",
    "    Args:\n",
    "        experiment_name (str): Nome do experimento\n",
    "        model: Modelo treinado\n",
    "        history: HistÃ³rico do treinamento\n",
    "        metrics (dict): MÃ©tricas de avaliaÃ§Ã£o\n",
    "        config (dict): ConfiguraÃ§Ãµes do experimento\n",
    "        save_dir (Path): DiretÃ³rio para salvar\n",
    "    \"\"\"\n",
    "    exp_dir = save_dir / experiment_name\n",
    "    exp_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Salvar modelo\n",
    "    model_path = exp_dir / \"modelo.h5\"\n",
    "    try:\n",
    "        if hasattr(model, 'save'):\n",
    "            model.save(model_path)\n",
    "        elif hasattr(model, 'save_weights'):\n",
    "            model.save_weights(model_path)\n",
    "        print(f\"ğŸ’¾ Modelo salvo em: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erro ao salvar modelo: {e}\")\n",
    "    \n",
    "    # Salvar histÃ³rico\n",
    "    history_path = exp_dir / \"historico.json\"\n",
    "    try:\n",
    "        # Converter numpy arrays para listas para serializaÃ§Ã£o JSON\n",
    "        history_dict = {}\n",
    "        if hasattr(history, 'history'):\n",
    "            for key, value in history.history.items():\n",
    "                if isinstance(value, (list, tuple)):\n",
    "                    history_dict[key] = value\n",
    "                elif hasattr(value, 'tolist'):\n",
    "                    history_dict[key] = value.tolist()\n",
    "                else:\n",
    "                    history_dict[key] = [float(value)]\n",
    "        \n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(history_dict, f, indent=2)\n",
    "        print(f\"ğŸ“ˆ HistÃ³rico salvo em: {history_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erro ao salvar histÃ³rico: {e}\")\n",
    "    \n",
    "    # Salvar mÃ©tricas e configuraÃ§Ãµes\n",
    "    results = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'backend': pinn_backend_name,\n",
    "        'metrics': metrics,\n",
    "        'config': config,\n",
    "        'physics_params': PHYSICS_PARAMS,\n",
    "        'network_config': NETWORK_CONFIG\n",
    "    }\n",
    "    \n",
    "    results_path = exp_dir / \"resultados.json\"\n",
    "    try:\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        print(f\"ğŸ“‹ Resultados salvos em: {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erro ao salvar resultados: {e}\")\n",
    "    \n",
    "    return exp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ¡ 4.5 EquaÃ§Ã£o de Calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para resolver a equaÃ§Ã£o de calor com estabilidade numÃ©rica\n",
    "\n",
    "\n",
    "def solve_heat_equation_1d_stable(x_span, t_span, current_profile, T_surface_profile, physics_params):\n",
    "    \"\"\"\n",
    "    Resolve a equaÃ§Ã£o de calor 1D com fonte IÂ²R usando diferenÃ§as finitas ESTÃVEL.\n",
    "    \n",
    "    Implementa ajuste automÃ¡tico do time step para garantir critÃ©rio CFL â‰¤ 0.5\n",
    "    \n",
    "    EquaÃ§Ã£o: âˆ‚T/âˆ‚t = Î± âˆ‚Â²T/âˆ‚xÂ² + (IÂ²R)/(Ïcp)\n",
    "    CondiÃ§Ãµes de contorno: T(0,t) = T_surface(t), âˆ‚T/âˆ‚x|_{x=L} = 0\n",
    "    \n",
    "    Args:\n",
    "        x_span (array): Vetor de posiÃ§Ã£o [m]\n",
    "        t_span (array): Vetor de tempo [s]  \n",
    "        current_profile (array): Perfil de corrente [A]\n",
    "        T_surface_profile (array): Perfil de temperatura da superfÃ­cie [Â°C]\n",
    "        physics_params (dict): ParÃ¢metros fÃ­sicos\n",
    "        \n",
    "    Returns:\n",
    "        array: Campo de temperatura T(x,t) [Â°C]\n",
    "    \"\"\"\n",
    "    # ParÃ¢metros\n",
    "    alpha = physics_params['alpha']\n",
    "    R = physics_params['R']\n",
    "    rho_cp = physics_params['rho_cp']\n",
    "    \n",
    "    # DiscretizaÃ§Ã£o original\n",
    "    nx = len(x_span)\n",
    "    nt = len(t_span)\n",
    "    dx = x_span[1] - x_span[0] if len(x_span) > 1 else physics_params['L']\n",
    "    dt_orig = t_span[1] - t_span[0] if len(t_span) > 1 else 1.0\n",
    "    \n",
    "    # Ajustar dt para garantir estabilidade CFL\n",
    "    cfl_target = 0.4  # Margem de seguranÃ§a\n",
    "    dt_stable = cfl_target * dx**2 / alpha\n",
    "    \n",
    "    # Se dt original for muito grande, usar subdivisÃµes temporais\n",
    "    if dt_orig > dt_stable:\n",
    "        n_substeps = int(np.ceil(dt_orig / dt_stable))\n",
    "        dt = dt_orig / n_substeps\n",
    "        print(f\"ğŸ”§ Ajuste CFL: dt_orig={dt_orig:.3f}s â†’ dt={dt:.3f}s ({n_substeps} substeps)\")\n",
    "    else:\n",
    "        n_substeps = 1\n",
    "        dt = dt_orig\n",
    "    \n",
    "    # Verificar estabilidade final\n",
    "    cfl = alpha * dt / dx**2\n",
    "    print(f\"âœ… CFL final = {cfl:.3f} (alvo: â‰¤ 0.5)\")\n",
    "    \n",
    "    # Inicializar campo de temperatura\n",
    "    T = np.zeros((nx, nt))\n",
    "    \n",
    "    # CondiÃ§Ã£o inicial (temperatura ambiente)\n",
    "    T_ambient = 25.0  # Â°C\n",
    "    T[:, 0] = T_ambient\n",
    "    \n",
    "    # Resolver por diferenÃ§as finitas com substeps\n",
    "    for i in range(1, nt):\n",
    "        # Estado atual (cÃ³pia para substeps)\n",
    "        T_current = T[:, i-1].copy()\n",
    "        \n",
    "        # Executar substeps temporais\n",
    "        for substep in range(n_substeps):\n",
    "            # Ãndice temporal para interpolaÃ§Ã£o\n",
    "            t_frac = (substep + 1) / n_substeps\n",
    "            \n",
    "            # Interpolar corrente e temperatura da superfÃ­cie\n",
    "            if i < nt - 1:\n",
    "                I_interp = current_profile[i-1] + t_frac * (current_profile[i] - current_profile[i-1])\n",
    "                T_surf_interp = T_surface_profile[i-1] + t_frac * (T_surface_profile[i] - T_surface_profile[i-1])\n",
    "            else:\n",
    "                I_interp = current_profile[i-1]\n",
    "                T_surf_interp = T_surface_profile[i-1]\n",
    "            \n",
    "            # Termo fonte: IÂ²R (limitado para evitar instabilidade)\n",
    "            source_term = (I_interp**2 * R) / rho_cp\n",
    "            source_term = np.clip(source_term, 0, 50)  # Limitar a 50 K/s\n",
    "            \n",
    "            # CondiÃ§Ã£o de contorno: T(0,t) = T_surface(t)\n",
    "            T_current[0] = T_surf_interp\n",
    "            \n",
    "            # Estado temporÃ¡rio para atualizaÃ§Ã£o\n",
    "            T_new = T_current.copy()\n",
    "            \n",
    "            # Pontos internos\n",
    "            for j in range(1, nx-1):\n",
    "                # Derivada segunda em x\n",
    "                d2T_dx2 = (T_current[j+1] - 2*T_current[j] + T_current[j-1]) / dx**2\n",
    "                \n",
    "                # EquaÃ§Ã£o de calor\n",
    "                dT_dt = alpha * d2T_dx2 + source_term\n",
    "                T_new[j] = T_current[j] + dt * dT_dt\n",
    "                \n",
    "                # Limitar temperatura fÃ­sica (evitar valores absurdos)\n",
    "                T_new[j] = np.clip(T_new[j], T_ambient - 10, T_ambient + 150)\n",
    "            \n",
    "            # CondiÃ§Ã£o de contorno: âˆ‚T/âˆ‚x|_{x=L} = 0 (derivada nula)\n",
    "            T_new[nx-1] = T_new[nx-2]\n",
    "            \n",
    "            # Atualizar estado\n",
    "            T_current = T_new\n",
    "        \n",
    "        # Salvar resultado final do passo temporal\n",
    "        T[:, i] = T_current\n",
    "        \n",
    "        # Verificar estabilidade (detectar divergÃªncia)\n",
    "        if np.any(np.isnan(T[:, i])) or np.any(np.isinf(T[:, i])):\n",
    "            print(f\"âš ï¸ Instabilidade detectada no tempo t={t_span[i]:.1f}s - aplicando correÃ§Ã£o\")\n",
    "            # Aplicar correÃ§Ã£o: usar valor anterior\n",
    "            T[:, i] = T[:, i-1]\n",
    "        elif np.max(T[:, i]) > T_ambient + 200:\n",
    "            print(f\"âš ï¸ Temperatura excessiva detectada: {np.max(T[:, i]):.1f}Â°C - limitando\")\n",
    "            # Limitar crescimento\n",
    "            T[:, i] = np.clip(T[:, i], T_ambient - 10, T_ambient + 150)\n",
    "    \n",
    "    print(f\"ğŸŒ¡ï¸ Faixa de temperatura final: {np.min(T):.1f} - {np.max(T):.1f} Â°C\")\n",
    "    return T\n",
    "\n",
    "print(\"âœ… FunÃ§Ã£o de soluÃ§Ã£o estÃ¡vel definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“’ 5. GeraÃ§Ã£o e Carregamento de Dados\n",
    "\n",
    "### 5.1 Dados SintÃ©ticos (Experimento E1)\n",
    "ImplementaÃ§Ã£o da soluÃ§Ã£o numÃ©rica da equaÃ§Ã£o de calor 1D com fonte IÂ²R para gerar dados sintÃ©ticos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_current_profile(t_span, profile_type=\"mixed\"):\n",
    "    \"\"\"\n",
    "    Gera perfis de corrente variados para simulaÃ§Ã£o.\n",
    "    \n",
    "    Args:\n",
    "        t_span (array): Vetor de tempo [s]\n",
    "        profile_type (str): Tipo de perfil (\"step\", \"ramp\", \"sine\", \"mixed\")\n",
    "        \n",
    "    Returns:\n",
    "        array: Perfil de corrente [A]\n",
    "    \"\"\"\n",
    "    t = t_span\n",
    "    \n",
    "    if profile_type == \"step\":\n",
    "        # Perfil de degraus\n",
    "        current = np.ones_like(t) * 10.0  # Base 10A\n",
    "        current[t > 300] = 15.0   # Degrau para 15A apÃ³s 5 min\n",
    "        current[t > 600] = 8.0    # Degrau para 8A apÃ³s 10 min\n",
    "        current[t > 900] = 12.0   # Degrau para 12A apÃ³s 15 min\n",
    "        \n",
    "    elif profile_type == \"ramp\":\n",
    "        # Perfil de rampa\n",
    "        current = 5.0 + (t / t.max()) * 10.0  # Rampa de 5A a 15A\n",
    "        \n",
    "    elif profile_type == \"sine\":\n",
    "        # Perfil senoidal\n",
    "        current = 10.0 + 5.0 * np.sin(2 * np.pi * t / 600)  # PerÃ­odo 10 min\n",
    "        \n",
    "    elif profile_type == \"mixed\":\n",
    "        # Perfil misto (mais realista)\n",
    "        current = np.ones_like(t) * 8.0  # Base 8A\n",
    "        # Adicionar variaÃ§Ãµes periÃ³dicas\n",
    "        current += 3.0 * np.sin(2 * np.pi * t / 300)  # VariaÃ§Ã£o lenta\n",
    "        current += 1.0 * np.sin(2 * np.pi * t / 60)   # VariaÃ§Ã£o rÃ¡pida\n",
    "        # Adicionar degraus ocasionais\n",
    "        current[t > 400] += 2.0\n",
    "        current[t > 800] -= 3.0\n",
    "        # Garantir valores positivos\n",
    "        current = np.maximum(current, 2.0)\n",
    "        \n",
    "    else:\n",
    "        # Perfil constante\n",
    "        current = np.ones_like(t) * 10.0\n",
    "    \n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a19034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, experiment_name, save_dir=None):\n",
    "    \"\"\"\n",
    "    Plota as curvas de aprendizado do treinamento.\n",
    "    \n",
    "    Args:\n",
    "        history: HistÃ³rico do treinamento\n",
    "        experiment_name (str): Nome do experimento\n",
    "        save_dir (Path): DiretÃ³rio para salvar o plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Curvas de Aprendizado - {experiment_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss total\n",
    "    axes[0, 0].plot(history.history['loss'], label='Treino', linewidth=2)\n",
    "    if 'val_loss' in history.history:\n",
    "        axes[0, 0].plot(history.history['val_loss'], label='ValidaÃ§Ã£o', linewidth=2)\n",
    "    axes[0, 0].set_title('Perda Total')\n",
    "    axes[0, 0].set_xlabel('Ã‰poca')\n",
    "    axes[0, 0].set_ylabel('Perda')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE (se disponÃ­vel)\n",
    "    if 'mae' in history.history:\n",
    "        axes[0, 1].plot(history.history['mae'], label='Treino MAE', linewidth=2)\n",
    "        if 'val_mae' in history.history:\n",
    "            axes[0, 1].plot(history.history['val_mae'], label='ValidaÃ§Ã£o MAE', linewidth=2)\n",
    "        axes[0, 1].set_title('Erro Absoluto MÃ©dio')\n",
    "        axes[0, 1].set_xlabel('Ã‰poca')\n",
    "        axes[0, 1].set_ylabel('MAE [Â°C]')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'MAE nÃ£o disponÃ­vel', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "        axes[0, 1].set_title('MAE nÃ£o registrado')\n",
    "    \n",
    "    # Learning rate (se disponÃ­vel)\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 0].plot(history.history['lr'], linewidth=2, color='orange')\n",
    "        axes[1, 0].set_title('Taxa de Aprendizado')\n",
    "        axes[1, 0].set_xlabel('Ã‰poca')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'LR nÃ£o disponÃ­vel', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        axes[1, 0].set_title('Learning Rate nÃ£o registrado')\n",
    "    \n",
    "    # Componentes da perda PINN (se disponÃ­vel)\n",
    "    loss_components = [key for key in history.history.keys() if 'loss' in key and key != 'loss' and 'val' not in key]\n",
    "    if loss_components:\n",
    "        for component in loss_components:\n",
    "            axes[1, 1].plot(history.history[component], label=component.replace('_', ' ').title(), linewidth=2)\n",
    "        axes[1, 1].set_title('Componentes da Perda PINN')\n",
    "        axes[1, 1].set_xlabel('Ã‰poca')\n",
    "        axes[1, 1].set_ylabel('Perda')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Componentes nÃ£o disponÃ­veis', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Componentes da Perda nÃ£o registrados')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        save_path = save_dir / f\"{experiment_name}_training_curves.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ“Š Curvas de aprendizado salvas em: {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_vs_actual(y_true, y_pred, experiment_name, save_dir=None):\n",
    "    \"\"\"\n",
    "    Plota prediÃ§Ãµes vs valores reais com mÃ©tricas.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array): Valores reais\n",
    "        y_pred (array): Valores preditos  \n",
    "        experiment_name (str): Nome do experimento\n",
    "        save_dir (Path): DiretÃ³rio para salvar o plot\n",
    "    \"\"\"\n",
    "    metrics = calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6, s=20)\n",
    "    \n",
    "    # Linha diagonal perfeita\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='PrediÃ§Ã£o Perfeita')\n",
    "    \n",
    "    plt.xlabel('Temperatura Real [Â°C]')\n",
    "    plt.ylabel('Temperatura Predita [Â°C]')\n",
    "    plt.title(f'{experiment_name} - PrediÃ§Ãµes vs Real')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adicionar mÃ©tricas no plot\n",
    "    textstr = f'MAE: {metrics[\"MAE\"]:.2f}Â°C\\nRMSE: {metrics[\"RMSE\"]:.2f}Â°C\\nPearson r: {metrics[\"Pearson_r\"]:.3f}'\n",
    "    plt.gca().text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    # Histograma dos resÃ­duos\n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = y_true - y_pred\n",
    "    plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('ResÃ­duos [Â°C]')\n",
    "    plt.ylabel('FrequÃªncia')\n",
    "    plt.title('DistribuiÃ§Ã£o dos ResÃ­duos')\n",
    "    plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # EstatÃ­sticas dos resÃ­duos\n",
    "    mean_residual = np.mean(residuals)\n",
    "    std_residual = np.std(residuals)\n",
    "    textstr_res = f'MÃ©dia: {mean_residual:.3f}Â°C\\nDesvio: {std_residual:.3f}Â°C'\n",
    "    plt.gca().text(0.95, 0.95, textstr_res, transform=plt.gca().transAxes, fontsize=10,\n",
    "                   horizontalalignment='right', verticalalignment='top', \n",
    "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_dir:\n",
    "        save_path = save_dir / f\"{experiment_name}_predictions.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"ğŸ“Š Plot de prediÃ§Ãµes salvo em: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1330a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_results(experiment_name, model, history, metrics, config, save_dir):\n",
    "    \"\"\"\n",
    "    Salva os resultados de um experimento em disco.\n",
    "    \n",
    "    Args:\n",
    "        experiment_name (str): Nome do experimento\n",
    "        model: Modelo treinado\n",
    "        history: HistÃ³rico do treinamento\n",
    "        metrics (dict): MÃ©tricas de avaliaÃ§Ã£o\n",
    "        config (dict): ConfiguraÃ§Ãµes do experimento\n",
    "        save_dir (Path): DiretÃ³rio para salvar\n",
    "    \"\"\"\n",
    "    exp_dir = save_dir / experiment_name\n",
    "    exp_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Salvar modelo\n",
    "    model_path = exp_dir / \"modelo.h5\"\n",
    "    try:\n",
    "        if hasattr(model, 'save'):\n",
    "            model.save(model_path)\n",
    "        elif hasattr(model, 'save_weights'):\n",
    "            model.save_weights(model_path)\n",
    "        print(f\"ğŸ’¾ Modelo salvo em: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erro ao salvar modelo: {e}\")\n",
    "    \n",
    "    # Salvar histÃ³rico\n",
    "    history_path = exp_dir / \"historico.json\"\n",
    "    try:\n",
    "        # Converter numpy arrays para listas para serializaÃ§Ã£o JSON\n",
    "        history_dict = {}\n",
    "        if hasattr(history, 'history'):\n",
    "            for key, value in history.history.items():\n",
    "                if isinstance(value, (list, tuple)):\n",
    "                    history_dict[key] = value\n",
    "                elif hasattr(value, 'tolist'):\n",
    "                    history_dict[key] = value.tolist()\n",
    "                else:\n",
    "                    history_dict[key] = [float(value)]\n",
    "        \n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(history_dict, f, indent=2)\n",
    "        print(f\"ğŸ“ˆ HistÃ³rico salvo em: {history_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erro ao salvar histÃ³rico: {e}\")\n",
    "    \n",
    "    # Salvar mÃ©tricas e configuraÃ§Ãµes\n",
    "    results = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'backend': pinn_backend_name,\n",
    "        'metrics': metrics,\n",
    "        'config': config,\n",
    "        'physics_params': PHYSICS_PARAMS,\n",
    "        'network_config': NETWORK_CONFIG\n",
    "    }\n",
    "    \n",
    "    results_path = exp_dir / \"resultados.json\"\n",
    "    try:\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        print(f\"ğŸ“‹ Resultados salvos em: {results_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erro ao salvar resultados: {e}\")\n",
    "    \n",
    "    return exp_dir\n",
    "\n",
    "print(\"âœ… FunÃ§Ãµes utilitÃ¡rias definidas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ GERAÃ‡ÃƒO DE DADOS SINTÃ‰TICOS FISICAMENTE REALISTAS\n",
    "\n",
    "\n",
    "def generate_realistic_motor_data(n_samples=800, add_noise=True):\n",
    "    \"\"\"\n",
    "    Gera dados sintÃ©ticos REALISTAS para motores elÃ©tricos baseado em:\n",
    "    - Perfis tÃ­picos de corrente industrial (5-15A)\n",
    "    - Temperaturas realistas (25-120Â°C)\n",
    "    - DinÃ¢mica tÃ©rmica correta (constantes de tempo ~minutos)\n",
    "    - Gradientes espaciais adequados\n",
    "    \n",
    "    Args:\n",
    "        n_samples (int): NÃºmero de amostras temporais\n",
    "        add_noise (bool): Se True, adiciona ruÃ­do de sensores\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dados sintÃ©ticos realistas\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ Gerando {n_samples} amostras REALISTAS de motor elÃ©trico...\")\n",
    "    \n",
    "    # DomÃ­nio espacial e temporal\n",
    "    L = PHYSICS_PARAMS['L']  # 20 mm\n",
    "    x_span = np.linspace(0, L, 21)  # 21 pontos espaciais\n",
    "    t_span = np.linspace(0, 1200, n_samples)  # 20 minutos\n",
    "    dt = t_span[1] - t_span[0]\n",
    "    \n",
    "    # 1. PERFIL DE CORRENTE REALISTA\n",
    "    current_profile = generate_current_profile(t_span, \"mixed\")\n",
    "    # Garantir faixa realista: 3-15A\n",
    "    current_profile = np.clip(current_profile, 3.0, 15.0)\n",
    "    \n",
    "    # 2. TEMPERATURA DA SUPERFÃCIE REALISTA\n",
    "    T_ambient = 25.0  # Â°C\n",
    "    T_surface_profile = np.zeros_like(t_span)\n",
    "    T_surface_profile[0] = T_ambient\n",
    "    \n",
    "    # Modelo tÃ©rmico simplificado para superfÃ­cie (resposta rÃ¡pida)\n",
    "    tau_surface = 60.0  # segundos (constante de tempo da superfÃ­cie)\n",
    "    \n",
    "    for i in range(1, len(t_span)):\n",
    "        # Aquecimento por efeito Joule (limitado)\n",
    "        heat_generation = (current_profile[i]**2 * PHYSICS_PARAMS['R']) / 1000  # W -> limitado\n",
    "        steady_temp = T_ambient + min(heat_generation * 8, 70)  # MÃ¡ximo 95Â°C\n",
    "        \n",
    "        # DinÃ¢mica de primeira ordem\n",
    "        dT_dt = (steady_temp - T_surface_profile[i-1]) / tau_surface\n",
    "        T_surface_profile[i] = T_surface_profile[i-1] + dt * dT_dt\n",
    "        \n",
    "        # Limitar temperatura da superfÃ­cie (fisicamente realista)\n",
    "        T_surface_profile[i] = np.clip(T_surface_profile[i], T_ambient, T_ambient + 75)\n",
    "    \n",
    "    # Adicionar variaÃ§Ã£o ambiental pequena\n",
    "    T_surface_profile += 2.0 * np.sin(2 * np.pi * t_span / 600)  # Ciclo lento\n",
    "    \n",
    "    # 3. RESOLVER EQUAÃ‡ÃƒO DE CALOR COM PARÃ‚METROS REALISTAS\n",
    "    # Ajustar parÃ¢metros para motor real\n",
    "    motor_params = PHYSICS_PARAMS.copy()\n",
    "    motor_params['alpha'] = 8e-5  # Menor difusividade (mais realista)\n",
    "    \n",
    "    print(f\"ğŸ”§ Resolvendo equaÃ§Ã£o de calor 1D...\")\n",
    "    T_field = solve_heat_equation_1d_stable(x_span, t_span, current_profile, T_surface_profile, motor_params)\n",
    "    \n",
    "    # 4. EXTRAIR DADOS INTERNOS\n",
    "    x_center_idx = len(x_span) // 2\n",
    "    T_internal = T_field[x_center_idx, :]\n",
    "    \n",
    "    # Verificar realismo dos resultados\n",
    "    max_temp = np.max(T_field)\n",
    "    if max_temp > 200:\n",
    "        print(f\"âš ï¸ Temperatura muito alta detectada ({max_temp:.1f}Â°C) - aplicando correÃ§Ã£o\")\n",
    "        T_field = np.clip(T_field, T_ambient, T_ambient + 100)\n",
    "        T_internal = T_field[x_center_idx, :]\n",
    "    \n",
    "    # 5. PREPARAR DADOS PARA PINN\n",
    "    X_mesh, T_mesh = np.meshgrid(x_span, t_span, indexing='ij')\n",
    "    \n",
    "    x_data = X_mesh.flatten()\n",
    "    t_data = T_mesh.flatten()\n",
    "    T_data = T_field.flatten()\n",
    "    \n",
    "    # Expandir variÃ¡veis para grade completa\n",
    "    I_data = np.tile(current_profile, len(x_span))\n",
    "    T_surf_data = np.tile(T_surface_profile, len(x_span))\n",
    "    \n",
    "    # 6. ADICIONAR RUÃDO REALISTA DE SENSORES\n",
    "    if add_noise:\n",
    "        # RuÃ­do tÃ­pico de termopares industriais\n",
    "        temp_noise = np.random.normal(0, NOISE_PARAMS['temp_noise_std'], T_data.shape)\n",
    "        T_data += temp_noise\n",
    "        \n",
    "        # RuÃ­do tÃ­pico de sensores de corrente\n",
    "        current_noise = np.random.normal(1, NOISE_PARAMS['current_noise_pct'], I_data.shape)\n",
    "        I_data *= current_noise\n",
    "        \n",
    "        print(f\"âœ… RuÃ­do de sensores: Â±{NOISE_PARAMS['temp_noise_std']}Â°C, Â±{NOISE_PARAMS['current_noise_pct']*100}%\")\n",
    "    \n",
    "    # 7. VERIFICAÃ‡Ã•ES DE SANIDADE\n",
    "    print(f\"ğŸ” VerificaÃ§Ãµes de qualidade:\")\n",
    "    print(f\"   Corrente: {np.min(I_data):.1f} - {np.max(I_data):.1f} A\")\n",
    "    print(f\"   T_superfÃ­cie: {np.min(T_surface_profile):.1f} - {np.max(T_surface_profile):.1f} Â°C\")\n",
    "    print(f\"   T_interna: {np.min(T_internal):.1f} - {np.max(T_internal):.1f} Â°C\")\n",
    "    print(f\"   T_campo: {np.min(T_data):.1f} - {np.max(T_data):.1f} Â°C\")\n",
    "    \n",
    "    # Aplicar clipping final para garantir fÃ­sica\n",
    "    T_data = np.clip(T_data, T_ambient - 5, T_ambient + 120)\n",
    "    \n",
    "    # 8. NORMALIZAÃ‡ÃƒO SEGURA\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_t = MinMaxScaler()\n",
    "    scaler_I = MinMaxScaler()\n",
    "    scaler_T = MinMaxScaler()\n",
    "    \n",
    "    x_norm = scaler_x.fit_transform(x_data.reshape(-1, 1)).flatten()\n",
    "    t_norm = scaler_t.fit_transform(t_data.reshape(-1, 1)).flatten()\n",
    "    I_norm = scaler_I.fit_transform(I_data.reshape(-1, 1)).flatten()\n",
    "    T_norm = scaler_T.fit_transform(T_data.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # 9. ESTRUTURA DE DADOS FINAL\n",
    "    data = {\n",
    "        'x': x_data, 't': t_data, 'I': I_data, 'T_surface': T_surf_data, 'T_internal': T_data,\n",
    "        'x_norm': x_norm, 't_norm': t_norm, 'I_norm': I_norm, 'T_norm': T_norm,\n",
    "        'scalers': {'x': scaler_x, 't': scaler_t, 'I': scaler_I, 'T': scaler_T},\n",
    "        'x_span': x_span, 't_span': t_span, 'T_field': T_field,\n",
    "        'current_profile': current_profile, 'T_surface_profile': T_surface_profile,\n",
    "        'T_internal_1d': T_internal\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Dados REALISTAS gerados:\")\n",
    "    print(f\"   Pontos totais: {len(x_data):,}\")\n",
    "    print(f\"   Faixa tÃ©rmica: {np.min(T_data):.1f} - {np.max(T_data):.1f} Â°C âœ“\")\n",
    "    print(f\"   Faixa corrente: {np.min(I_data):.1f} - {np.max(I_data):.1f} A âœ“\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# GERAR DADOS MOCK PARA EXPERIMENTOS E2 e E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mock_datasets():\n",
    "    \"\"\"Cria datasets mock para validaÃ§Ã£o e teste.\"\"\"\n",
    "    print(\"ğŸ”„ Criando datasets mock para experimentos...\")\n",
    "    \n",
    "    # Dataset de validaÃ§Ã£o (E2)\n",
    "    validation_data = generate_realistic_motor_data(n_samples=400, add_noise=True)\n",
    "    \n",
    "    # Dataset de teste (E3) - perfil diferente\n",
    "    test_data = generate_realistic_motor_data(n_samples=300, add_noise=True)\n",
    "    \n",
    "    return validation_data, test_data\n",
    "\n",
    "# EXECUTAR GERAÃ‡ÃƒO COMPLETA\n",
    "try:\n",
    "    print(\"ğŸš€ Gerando todos os datasets...\")\n",
    "    \n",
    "    # Dados sintÃ©ticos principais (E1)\n",
    "    synthetic_data = generate_realistic_motor_data(n_samples=800, add_noise=True)\n",
    "    \n",
    "    # Dados mock para outros experimentos\n",
    "    validation_data, test_data = create_mock_datasets()\n",
    "    \n",
    "    print(\"âœ… TODOS OS DATASETS GERADOS COM SUCESSO!\")\n",
    "    print(\"   - synthetic_data: Experimento E1 (aprendizagem PDE)\")\n",
    "    print(\"   - validation_data: Experimento E2 (ajuste parÃ¢metros)\")\n",
    "    print(\"   - test_data: Experimento E3 (inferÃªncia)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro na geraÃ§Ã£o: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c239858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š VISUALIZAÃ‡ÃƒO DOS DADOS REALISTAS CORRIGIDOS\n",
    "\n",
    "# Verificar se os dados foram gerados corretamente\n",
    "if 'synthetic_data' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('âœ… Dados SintÃ©ticos REALISTAS - Motor ElÃ©trico', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Perfil de corrente\n",
    "    axes[0, 0].plot(synthetic_data['t_span'], synthetic_data['current_profile'], linewidth=2, color='blue')\n",
    "    axes[0, 0].set_title('Perfil de Corrente (Realista)')\n",
    "    axes[0, 0].set_xlabel('Tempo [s]')\n",
    "    axes[0, 0].set_ylabel('Corrente [A]')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_ylim(0, 20)  # Faixa realista\n",
    "\n",
    "    # Perfil de temperatura da superfÃ­cie\n",
    "    axes[0, 1].plot(synthetic_data['t_span'], synthetic_data['T_surface_profile'], linewidth=2, color='red')\n",
    "    axes[0, 1].set_title('Temperatura da SuperfÃ­cie (Realista)')\n",
    "    axes[0, 1].set_xlabel('Tempo [s]')\n",
    "    axes[0, 1].set_ylabel('Temperatura [Â°C]')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(20, 120)  # Faixa realista\n",
    "\n",
    "    # Temperatura interna (centro)\n",
    "    axes[1, 0].plot(synthetic_data['t_span'], synthetic_data['T_internal_1d'], linewidth=2, color='green')\n",
    "    axes[1, 0].set_title('Temperatura Interna (Centro)')\n",
    "    axes[1, 0].set_xlabel('Tempo [s]')\n",
    "    axes[1, 0].set_ylabel('Temperatura [Â°C]')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(20, 120)  # Faixa realista\n",
    "\n",
    "    # Campo de temperatura T(x,t) - heatmap\n",
    "    im = axes[1, 1].imshow(synthetic_data['T_field'], aspect='auto', origin='lower', \n",
    "                          cmap='hot', vmin=25, vmax=100)\n",
    "    axes[1, 1].set_title('Campo de Temperatura T(x,t)')\n",
    "    axes[1, 1].set_xlabel('Tempo [amostras]')\n",
    "    axes[1, 1].set_ylabel('PosiÃ§Ã£o [amostras]')\n",
    "    cbar = plt.colorbar(im, ax=axes[1, 1], label='Temperatura [Â°C]')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # EstatÃ­sticas dos dados\n",
    "    print(\"\\nğŸ“Š ESTATÃSTICAS DOS DADOS REALISTAS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"ğŸ“ˆ Corrente:\")\n",
    "    print(f\"   Min: {np.min(synthetic_data['current_profile']):.1f} A\")\n",
    "    print(f\"   Max: {np.max(synthetic_data['current_profile']):.1f} A\")\n",
    "    print(f\"   MÃ©dia: {np.mean(synthetic_data['current_profile']):.1f} A\")\n",
    "    \n",
    "    print(f\"\\nğŸŒ¡ï¸ Temperatura da SuperfÃ­cie:\")\n",
    "    print(f\"   Min: {np.min(synthetic_data['T_surface_profile']):.1f} Â°C\")\n",
    "    print(f\"   Max: {np.max(synthetic_data['T_surface_profile']):.1f} Â°C\")\n",
    "    print(f\"   MÃ©dia: {np.mean(synthetic_data['T_surface_profile']):.1f} Â°C\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¥ Temperatura Interna:\")\n",
    "    print(f\"   Min: {np.min(synthetic_data['T_internal_1d']):.1f} Â°C\")\n",
    "    print(f\"   Max: {np.max(synthetic_data['T_internal_1d']):.1f} Â°C\")\n",
    "    print(f\"   MÃ©dia: {np.mean(synthetic_data['T_internal_1d']):.1f} Â°C\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Campo TÃ©rmico Completo:\")\n",
    "    print(f\"   Min: {np.min(synthetic_data['T_field']):.1f} Â°C\")\n",
    "    print(f\"   Max: {np.max(synthetic_data['T_field']):.1f} Â°C\")\n",
    "    print(f\"   Gradiente mÃ¡ximo: {np.max(synthetic_data['T_field']) - np.min(synthetic_data['T_field']):.1f} Â°C\")\n",
    "    \n",
    "    # VerificaÃ§Ã£o de realismo\n",
    "    current_ok = 3 <= np.min(synthetic_data['current_profile']) and np.max(synthetic_data['current_profile']) <= 20\n",
    "    temp_surface_ok = 20 <= np.min(synthetic_data['T_surface_profile']) and np.max(synthetic_data['T_surface_profile']) <= 150\n",
    "    temp_internal_ok = 20 <= np.min(synthetic_data['T_internal_1d']) and np.max(synthetic_data['T_internal_1d']) <= 150\n",
    "    \n",
    "    print(f\"\\nâœ… VERIFICAÃ‡ÃƒO DE REALISMO:\")\n",
    "    print(f\"   Corrente realista (3-20A): {'âœ“' if current_ok else 'âœ—'}\")\n",
    "    print(f\"   Temp. superfÃ­cie realista (20-150Â°C): {'âœ“' if temp_surface_ok else 'âœ—'}\")\n",
    "    print(f\"   Temp. interna realista (20-150Â°C): {'âœ“' if temp_internal_ok else 'âœ—'}\")\n",
    "    \n",
    "    if current_ok and temp_surface_ok and temp_internal_ok:\n",
    "        print(\"\\nğŸ‰ DADOS COMPLETAMENTE REALISTAS! Prontos para treinar PINN.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Alguns dados ainda fora da faixa realista - ajustar parÃ¢metros.\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Dados sintÃ©ticos nÃ£o encontrados. Execute a cÃ©lula anterior primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Dados Reais (Mock para Experimentos E2 e E3)\n",
    "ImplementaÃ§Ã£o de dados mock baseados em SCADA para os experimentos E2 e E3. Na prÃ¡tica, estes dados seriam carregados de arquivos CSV reais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 6. ImplementaÃ§Ã£o do PINN\n",
    "\n",
    "### 6.1 DefiniÃ§Ã£o da Arquitetura\n",
    "ImplementaÃ§Ã£o da rede neural e funÃ§Ã£o de perda customizada para o PINN, com fallback automÃ¡tico entre backends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13934032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ CLASSE PINN UNIFICADA COM FALLBACK E CORREÃ‡Ã•ES DE BUGS\n",
    "\n",
    "\n",
    "class PINN:\n",
    "    \"\"\"\n",
    "    ImplementaÃ§Ã£o unificada de Physics-Informed Neural Network (PINN).\n",
    "    \n",
    "    Features:\n",
    "    - Suporte para mÃºltiplos backends (DeepXDE, SciANN, TensorFlow manual)\n",
    "    - CorreÃ§Ã£o de bugs de conversÃ£o tensor/numpy\n",
    "    - Interface consistente para todos os experimentos\n",
    "    - Callbacks e early stopping\n",
    "    - Logging detalhado\n",
    "    \n",
    "    Atributos:\n",
    "        physics_params (dict): ParÃ¢metros fÃ­sicos do motor\n",
    "        network_config (dict): ConfiguraÃ§Ã£o da arquitetura da rede\n",
    "        loss_weights (dict): Pesos das componentes da funÃ§Ã£o de perda\n",
    "        backend (str): Backend sendo utilizado ('deepxde', 'sciann', 'manual')\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, physics_params, network_config, loss_weights):\n",
    "        self.physics_params = physics_params\n",
    "        self.network_config = network_config\n",
    "        self.loss_weights = loss_weights\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.backend = None\n",
    "        self.callbacks = []\n",
    "        \n",
    "        # Detectar e configurar backend\n",
    "        self._setup_backend()\n",
    "        \n",
    "        # Criar modelo baseado no backend\n",
    "        self._build_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _build_model(self):\n",
    "        \"\"\"ConstrÃ³i a arquitetura da rede neural\"\"\"\n",
    "        model = Sequential([\n",
    "            Dense(self.network_config['neurons_per_layer'], \n",
    "                  activation=self.network_config['activation'], \n",
    "                  input_shape=(2,))  # (x, t)\n",
    "        ])\n",
    "        \n",
    "        # Camadas ocultas\n",
    "        for _ in range(self.network_config['hidden_layers'] - 1):\n",
    "            model.add(Dense(self.network_config['neurons_per_layer'], \n",
    "                           activation=self.network_config['activation']))\n",
    "        \n",
    "        # Camada de saÃ­da\n",
    "        model.add(Dense(1, activation=self.network_config['output_activation']))\n",
    "        \n",
    "        self.model = model\n",
    "        print(f\"ğŸ—ï¸ Modelo PINN manual criado: {self.model.count_params()} parÃ¢metros\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pde_loss(self, x, t, I):\n",
    "        \"\"\"\n",
    "        Calcula a perda da equaÃ§Ã£o diferencial parcial (PDE).\n",
    "        \n",
    "        EquaÃ§Ã£o de calor: âˆ‚T/âˆ‚t = Î± âˆ‚Â²T/âˆ‚xÂ² + IÂ²R/(Ïcp)\n",
    "        \"\"\"\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch([x, t])\n",
    "            with tf.GradientTape(persistent=True) as tape1:\n",
    "                tape1.watch([x, t])\n",
    "                inputs = tf.stack([x, t], axis=1)\n",
    "                T = self.model(inputs)\n",
    "            \n",
    "            # Primeira derivada\n",
    "            dT_dx = tape1.gradient(T, x)\n",
    "            dT_dt = tape1.gradient(T, t)\n",
    "        \n",
    "        # Segunda derivada\n",
    "        d2T_dx2 = tape2.gradient(dT_dx, x)\n",
    "        \n",
    "        # Termo fonte: IÂ²R/(Ïcp)\n",
    "        source_term = (I**2 * self.physics_params['R']) / self.physics_params['rho_cp']\n",
    "        \n",
    "        # ResÃ­duo da PDE\n",
    "        pde_residual = dT_dt - self.physics_params['alpha'] * d2T_dx2 - source_term\n",
    "        \n",
    "        return tf.reduce_mean(tf.square(pde_residual))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def boundary_loss(self, x, t, T_surface):\n",
    "        \"\"\"\n",
    "        Calcula a perda das condiÃ§Ãµes de contorno.\n",
    "        \n",
    "        BC1: T(0, t) = T_surface(t)\n",
    "        BC2: âˆ‚T/âˆ‚x|_{x=L} = 0\n",
    "        \"\"\"\n",
    "        # BC1: T(0, t) = T_surface(t)\n",
    "        x_boundary = tf.zeros_like(t)\n",
    "        inputs_bc1 = tf.stack([x_boundary, t], axis=1)\n",
    "        T_pred_bc1 = self.model(inputs_bc1)\n",
    "        bc1_loss = tf.reduce_mean(tf.square(T_pred_bc1 - T_surface))\n",
    "        \n",
    "        # BC2: âˆ‚T/âˆ‚x|_{x=L} = 0 (derivada nula no final)\n",
    "        x_end = tf.ones_like(t) * self.physics_params['L']\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_end)\n",
    "            inputs_bc2 = tf.stack([x_end, t], axis=1)\n",
    "            T_pred_bc2 = self.model(inputs_bc2)\n",
    "        \n",
    "        dT_dx_end = tape.gradient(T_pred_bc2, x_end)\n",
    "        bc2_loss = tf.reduce_mean(tf.square(dT_dx_end))\n",
    "        \n",
    "        return bc1_loss + bc2_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba753d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def data_loss(self, x, t, T_data):\n",
    "        \"\"\"Calcula a perda dos dados disponÃ­veis\"\"\"\n",
    "        inputs = tf.stack([x, t], axis=1)\n",
    "        T_pred = self.model(inputs)\n",
    "        return tf.reduce_mean(tf.square(T_pred - T_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def total_loss(self, x, t, I, T_surface, T_data):\n",
    "        \"\"\"Calcula a perda total do PINN\"\"\"\n",
    "        # Converter para tensores do TensorFlow\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        t = tf.convert_to_tensor(t, dtype=tf.float32)\n",
    "        I = tf.convert_to_tensor(I, dtype=tf.float32)\n",
    "        T_surface = tf.convert_to_tensor(T_surface, dtype=tf.float32)\n",
    "        T_data = tf.convert_to_tensor(T_data, dtype=tf.float32)\n",
    "        \n",
    "        # Calcular componentes da perda\n",
    "        loss_data = self.data_loss(x, t, T_data)\n",
    "        loss_pde = self.pde_loss(x, t, I)\n",
    "        loss_bc = self.boundary_loss(x, t, T_surface)\n",
    "        \n",
    "        # Perda total ponderada\n",
    "        total = (self.loss_weights['lambda_data'] * loss_data + \n",
    "                self.loss_weights['lambda_pde'] * loss_pde +\n",
    "                self.loss_weights['lambda_bc'] * loss_bc)\n",
    "        \n",
    "        return total, loss_data, loss_pde, loss_bc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485282b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_step(self, x, t, I, T_surface, T_data, optimizer):\n",
    "        \"\"\"Executa um passo de treinamento\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, loss_data, loss_pde, loss_bc = self.total_loss(x, t, I, T_surface, T_data)\n",
    "        \n",
    "        # Calcular gradientes e aplicar\n",
    "        gradients = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        \n",
    "        return total_loss, loss_data, loss_pde, loss_bc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, x_train, t_train, I_train, T_surface_train, T_train, \n",
    "              x_val=None, t_val=None, I_val=None, T_surface_val=None, T_val=None,\n",
    "              epochs=1000, learning_rate=1e-3, verbose=1):\n",
    "        \"\"\"\n",
    "        Treina o modelo PINN\n",
    "        \"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # HistÃ³rico do treinamento\n",
    "        history = {\n",
    "            'loss': [],\n",
    "            'data_loss': [],\n",
    "            'pde_loss': [],\n",
    "            'bc_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_data_loss': [],\n",
    "            'val_pde_loss': [],\n",
    "            'val_bc_loss': []\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸš€ Iniciando treinamento PINN manual - {epochs} Ã©pocas\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Treinamento\n",
    "            total_loss, loss_data, loss_pde, loss_bc = self.train_step(\n",
    "                x_train, t_train, I_train, T_surface_train, T_train, optimizer\n",
    "            )\n",
    "            \n",
    "            # Registrar perdas de treino\n",
    "            history['loss'].append(float(total_loss))\n",
    "            history['data_loss'].append(float(loss_data))\n",
    "            history['pde_loss'].append(float(loss_pde))\n",
    "            history['bc_loss'].append(float(loss_bc))\n",
    "            \n",
    "            # ValidaÃ§Ã£o (se fornecida)\n",
    "            if x_val is not None:\n",
    "                val_total_loss, val_loss_data, val_loss_pde, val_loss_bc = self.total_loss(\n",
    "                    x_val, t_val, I_val, T_surface_val, T_val\n",
    "                )\n",
    "                history['val_loss'].append(float(val_total_loss))\n",
    "                history['val_data_loss'].append(float(val_loss_data))\n",
    "                history['val_pde_loss'].append(float(val_loss_pde))\n",
    "                history['val_bc_loss'].append(float(val_loss_bc))\n",
    "            else:\n",
    "                # Preencher com zeros se nÃ£o hÃ¡ validaÃ§Ã£o\n",
    "                history['val_loss'].append(0.0)\n",
    "                history['val_data_loss'].append(0.0)\n",
    "                history['val_pde_loss'].append(0.0)\n",
    "                history['val_bc_loss'].append(0.0)\n",
    "            \n",
    "            # Log do progresso\n",
    "            if verbose and (epoch + 1) % max(1, epochs // 10) == 0:\n",
    "                print(f\"Ã‰poca {epoch+1}/{epochs} - \"\n",
    "                      f\"Loss: {total_loss:.4f} \"\n",
    "                      f\"(Data: {loss_data:.4f}, PDE: {loss_pde:.4f}, BC: {loss_bc:.4f})\")\n",
    "        \n",
    "        # Criar objeto similar ao history do Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "        class HistoryWrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042707b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "            def __init__(self, history_dict):\n",
    "                self.history = history_dict\n",
    "        \n",
    "        self.history = HistoryWrapper(history)\n",
    "        print(\"âœ… Treinamento PINN manual concluÃ­do\")\n",
    "        \n",
    "        return self.history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05baae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, x, t):\n",
    "        \"\"\"Faz prediÃ§Ãµes com o modelo treinado\"\"\"\n",
    "        inputs = tf.stack([x, t], axis=1)\n",
    "        return self.model(inputs).numpy()\n",
    "\n",
    "# FunÃ§Ã£o para criar PINN com fallback automÃ¡tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pinn_model(physics_params, network_config, loss_weights):\n",
    "    \"\"\"\n",
    "    Cria um modelo PINN usando o backend disponÃ­vel.\n",
    "    \"\"\"\n",
    "    if pinn_backend == \"deepxde\":\n",
    "        print(\"ğŸš€ Criando PINN com DeepXDE...\")\n",
    "        # ImplementaÃ§Ã£o com DeepXDE seria aqui\n",
    "        # Por simplicidade, vamos usar a implementaÃ§Ã£o manual\n",
    "        return PINN(physics_params, network_config, loss_weights)\n",
    "    \n",
    "    elif pinn_backend == \"sciann\":\n",
    "        print(\"ğŸš€ Criando PINN com SciANN...\")\n",
    "        # ImplementaÃ§Ã£o com SciANN seria aqui\n",
    "        # Por simplicidade, vamos usar a implementaÃ§Ã£o manual\n",
    "        return PINN(physics_params, network_config, loss_weights)\n",
    "    \n",
    "    else:\n",
    "        print(\"ğŸš€ Criando PINN manual com TensorFlow/Keras...\")\n",
    "        return PINN(physics_params, network_config, loss_weights)\n",
    "\n",
    "print(\"âœ… Classes e funÃ§Ãµes PINN definidas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ CLASSE PINN UNIFICADA - CORREÃ‡ÃƒO DEFINITIVA\n",
    "\n",
    "print(\"ğŸ”§ Criando implementaÃ§Ã£o definitiva e corrigida da classe PINN...\")\n",
    "\n",
    "\n",
    "class PINN:\n",
    "    \"\"\"\n",
    "    ImplementaÃ§Ã£o unificada de Physics-Informed Neural Network (PINN).\n",
    "    \n",
    "    Features:\n",
    "    - CorreÃ§Ã£o completa do bug .numpy() usando tf.keras.backend.get_value()\n",
    "    - Suporte para mÃºltiplos backends (DeepXDE, SciANN, TensorFlow manual)\n",
    "    - Interface consistente para todos os experimentos\n",
    "    - Callbacks e early stopping\n",
    "    - Logging detalhado\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, physics_params, network_config, loss_weights):\n",
    "        self.physics_params = physics_params\n",
    "        self.network_config = network_config\n",
    "        self.loss_weights = loss_weights\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.backend = None\n",
    "        \n",
    "        # Detectar e configurar backend\n",
    "        self._setup_backend()\n",
    "        \n",
    "        # Criar modelo baseado no backend\n",
    "        self._build_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0041ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _setup_backend(self):\n",
    "        \"\"\"Detecta e configura o backend disponÃ­vel\"\"\"\n",
    "        global pinn_backend\n",
    "        \n",
    "        if pinn_backend == \"deepxde\":\n",
    "            try:\n",
    "                import deepxde as dde\n",
    "                self.backend = \"deepxde\"\n",
    "                print(\"âœ… Usando backend DeepXDE\")\n",
    "            except:\n",
    "                self.backend = None\n",
    "        \n",
    "        elif pinn_backend == \"sciann\":\n",
    "            try:\n",
    "                import sciann as sn\n",
    "                self.backend = \"sciann\"\n",
    "                print(\"âœ… Usando backend SciANN\")\n",
    "            except:\n",
    "                self.backend = None\n",
    "        \n",
    "        # Fallback para implementaÃ§Ã£o manual\n",
    "        if self.backend is None:\n",
    "            self.backend = \"manual\"\n",
    "            print(\"âœ… Usando implementaÃ§Ã£o manual com TensorFlow/Keras\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _build_model(self):\n",
    "        \"\"\"ConstrÃ³i a arquitetura da rede neural baseada no backend\"\"\"\n",
    "        if self.backend == \"manual\":\n",
    "            self._build_manual_model()\n",
    "        else:\n",
    "            # Por enquanto, usa implementaÃ§Ã£o manual para todos\n",
    "            print(f\"ğŸ”„ {self.backend}: usando implementaÃ§Ã£o manual temporariamente\")\n",
    "            self._build_manual_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd55b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _build_manual_model(self):\n",
    "        \"\"\"ConstrÃ³i modelo usando TensorFlow/Keras puro\"\"\"\n",
    "        model = Sequential([\n",
    "            Dense(self.network_config['neurons_per_layer'], \n",
    "                  activation=self.network_config['activation'], \n",
    "                  input_shape=(2,))  # (x, t)\n",
    "        ])\n",
    "        \n",
    "        # Camadas ocultas\n",
    "        for _ in range(self.network_config['hidden_layers'] - 1):\n",
    "            model.add(Dense(self.network_config['neurons_per_layer'], \n",
    "                           activation=self.network_config['activation']))\n",
    "        \n",
    "        # Camada de saÃ­da\n",
    "        model.add(Dense(1, activation=self.network_config['output_activation']))\n",
    "        \n",
    "        self.model = model\n",
    "        print(f\"ğŸ—ï¸ Modelo PINN criado: {self.model.count_params()} parÃ¢metros\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2139564",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pde_loss(self, x, t, I):\n",
    "        \"\"\"Calcula a perda da equaÃ§Ã£o diferencial parcial (PDE)\"\"\"\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch([x, t])\n",
    "            with tf.GradientTape(persistent=True) as tape1:\n",
    "                tape1.watch([x, t])\n",
    "                inputs = tf.stack([x, t], axis=1)\n",
    "                T = self.model(inputs)\n",
    "            \n",
    "            # Primeira derivada\n",
    "            dT_dx = tape1.gradient(T, x)\n",
    "            dT_dt = tape1.gradient(T, t)\n",
    "        \n",
    "        # Segunda derivada\n",
    "        d2T_dx2 = tape2.gradient(dT_dx, x)\n",
    "        \n",
    "        # Termo fonte: IÂ²R/(Ïcp)\n",
    "        source_term = (I**2 * self.physics_params['R']) / self.physics_params['rho_cp']\n",
    "        \n",
    "        # ResÃ­duo da PDE\n",
    "        pde_residual = dT_dt - self.physics_params['alpha'] * d2T_dx2 - source_term\n",
    "        \n",
    "        return tf.reduce_mean(tf.square(pde_residual))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def boundary_loss(self, x, t, T_surface):\n",
    "        \"\"\"Calcula a perda das condiÃ§Ãµes de contorno\"\"\"\n",
    "        # BC1: T(0, t) = T_surface(t)\n",
    "        x_boundary = tf.zeros_like(t)\n",
    "        inputs_bc1 = tf.stack([x_boundary, t], axis=1)\n",
    "        T_pred_bc1 = self.model(inputs_bc1)\n",
    "        bc1_loss = tf.reduce_mean(tf.square(T_pred_bc1 - T_surface))\n",
    "        \n",
    "        # BC2: âˆ‚T/âˆ‚x|_{x=L} = 0 (derivada nula no final)\n",
    "        x_end = tf.ones_like(t) * self.physics_params['L']\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_end)\n",
    "            inputs_bc2 = tf.stack([x_end, t], axis=1)\n",
    "            T_pred_bc2 = self.model(inputs_bc2)\n",
    "        \n",
    "        dT_dx_end = tape.gradient(T_pred_bc2, x_end)\n",
    "        bc2_loss = tf.reduce_mean(tf.square(dT_dx_end))\n",
    "        \n",
    "        return bc1_loss + bc2_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def data_loss(self, x, t, T_data):\n",
    "        \"\"\"Calcula a perda dos dados disponÃ­veis\"\"\"\n",
    "        inputs = tf.stack([x, t], axis=1)\n",
    "        T_pred = self.model(inputs)\n",
    "        return tf.reduce_mean(tf.square(T_pred - T_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3109a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def total_loss(self, x, t, I, T_surface, T_data):\n",
    "        \"\"\"Calcula a perda total do PINN\"\"\"\n",
    "        # Converter para tensores do TensorFlow\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        t = tf.convert_to_tensor(t, dtype=tf.float32)\n",
    "        I = tf.convert_to_tensor(I, dtype=tf.float32)\n",
    "        T_surface = tf.convert_to_tensor(T_surface, dtype=tf.float32)\n",
    "        T_data = tf.convert_to_tensor(T_data, dtype=tf.float32)\n",
    "        \n",
    "        # Calcular componentes da perda\n",
    "        loss_data = self.data_loss(x, t, T_data)\n",
    "        loss_pde = self.pde_loss(x, t, I)\n",
    "        loss_bc = self.boundary_loss(x, t, T_surface)\n",
    "        \n",
    "        # Perda total ponderada\n",
    "        total = (self.loss_weights['lambda_data'] * loss_data + \n",
    "                self.loss_weights['lambda_pde'] * loss_pde +\n",
    "                self.loss_weights['lambda_bc'] * loss_bc)\n",
    "        \n",
    "        return total, loss_data, loss_pde, loss_bc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4997b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train_step(self, x, t, I, T_surface, T_data, optimizer):\n",
    "        \"\"\"Executa um passo de treinamento\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, loss_data, loss_pde, loss_bc = self.total_loss(x, t, I, T_surface, T_data)\n",
    "        \n",
    "        # Calcular gradientes e aplicar\n",
    "        gradients = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        \n",
    "        return total_loss, loss_data, loss_pde, loss_bc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _safe_get_value(self, tensor):\n",
    "        \"\"\"Converte tensor para float de forma segura, funcionando em modo eager e graph\"\"\"\n",
    "        try:\n",
    "            # Primeiro tenta com keras backend (funciona em ambos os modos)\n",
    "            return float(tf.keras.backend.get_value(tensor))\n",
    "        except:\n",
    "            try:\n",
    "                # Se falhar, tenta com .numpy() (modo eager)\n",
    "                return float(tensor.numpy())\n",
    "            except:\n",
    "                # Como Ãºltimo recurso, converte para Python float\n",
    "                return float(tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, x_train, t_train, I_train, T_surface_train, T_train,\n",
    "              x_val=None, t_val=None, I_val=None, T_surface_val=None, T_val=None,\n",
    "              epochs=1000, learning_rate=1e-3, verbose=1):\n",
    "        \"\"\"Treina o modelo PINN com callbacks suportados\"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # HistÃ³rico do treinamento\n",
    "        history = {\n",
    "            'loss': [],\n",
    "            'data_loss': [],\n",
    "            'pde_loss': [],\n",
    "            'bc_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_data_loss': [],\n",
    "            'val_pde_loss': [],\n",
    "            'val_bc_loss': [],\n",
    "            'lr': []\n",
    "        }\n",
    "        \n",
    "        # Early stopping manual\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        patience = EXPERIMENT_CONFIG.get('patience', 50)\n",
    "        \n",
    "        print(f\"ğŸš€ Iniciando treinamento PINN - {epochs} Ã©pocas\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Treinamento\n",
    "            total_loss, loss_data, loss_pde, loss_bc = self.train_step(\n",
    "                x_train, t_train, I_train, T_surface_train, T_train, optimizer\n",
    "            )\n",
    "            \n",
    "            # CORREÃ‡ÃƒO: Usar _safe_get_value ao invÃ©s de .numpy()\n",
    "            history['loss'].append(self._safe_get_value(total_loss))\n",
    "            history['data_loss'].append(self._safe_get_value(loss_data))\n",
    "            history['pde_loss'].append(self._safe_get_value(loss_pde))\n",
    "            history['bc_loss'].append(self._safe_get_value(loss_bc))\n",
    "            history['lr'].append(float(optimizer.learning_rate.numpy()))\n",
    "            \n",
    "            # ValidaÃ§Ã£o (se fornecida)\n",
    "            if x_val is not None and T_surface_val is not None:\n",
    "                val_total_loss, val_loss_data, val_loss_pde, val_loss_bc = self.total_loss(\n",
    "                    x_val, t_val, I_val, T_surface_val, T_val\n",
    "                )\n",
    "                # CORREÃ‡ÃƒO: Usar _safe_get_value\n",
    "                val_loss_float = self._safe_get_value(val_total_loss)\n",
    "                history['val_loss'].append(val_loss_float)\n",
    "                history['val_data_loss'].append(self._safe_get_value(val_loss_data))\n",
    "                history['val_pde_loss'].append(self._safe_get_value(val_loss_pde))\n",
    "                history['val_bc_loss'].append(self._safe_get_value(val_loss_bc))\n",
    "                \n",
    "                # Early stopping check\n",
    "                if val_loss_float < best_val_loss:\n",
    "                    best_val_loss = val_loss_float\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"ğŸ›‘ Early stopping na Ã©poca {epoch+1}\")\n",
    "                    break\n",
    "            else:\n",
    "                # Preencher com zeros se nÃ£o hÃ¡ validaÃ§Ã£o\n",
    "                history['val_loss'].append(0.0)\n",
    "                history['val_data_loss'].append(0.0)\n",
    "                history['val_pde_loss'].append(0.0)\n",
    "                history['val_bc_loss'].append(0.0)\n",
    "            \n",
    "            # Log do progresso\n",
    "            if verbose and (epoch + 1) % max(1, epochs // 10) == 0:\n",
    "                loss_str = f\"Loss: {self._safe_get_value(total_loss):.4f}\"\n",
    "                loss_str += f\" (Data: {self._safe_get_value(loss_data):.4f}\"\n",
    "                loss_str += f\", PDE: {self._safe_get_value(loss_pde):.4f}\"\n",
    "                loss_str += f\", BC: {self._safe_get_value(loss_bc):.4f})\"\n",
    "                print(f\"Ã‰poca {epoch+1}/{epochs} - {loss_str}\")\n",
    "        \n",
    "        # Criar objeto similar ao history do Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eec64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        class HistoryWrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "            def __init__(self, history_dict):\n",
    "                self.history = history_dict\n",
    "        \n",
    "        self.history = HistoryWrapper(history)\n",
    "        print(\"âœ… Treinamento PINN concluÃ­do\")\n",
    "        \n",
    "        return self.history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf68710",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, x, t):\n",
    "        \"\"\"Faz prediÃ§Ãµes com o modelo treinado\"\"\"\n",
    "        inputs = tf.stack([x, t], axis=1)\n",
    "        predictions = self.model(inputs)\n",
    "        # Usar numpy() aqui Ã© seguro pois Ã© executado em modo eager\n",
    "        return predictions.numpy()\n",
    "\n",
    "# FunÃ§Ã£o factory atualizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66cc487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pinn_model(physics_params, network_config, loss_weights):\n",
    "    \"\"\"Cria um modelo PINN usando a classe unificada\"\"\"\n",
    "    return PINN(physics_params, network_config, loss_weights)\n",
    "\n",
    "# FunÃ§Ã£o de compatibilidade com cÃ³digo existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pinn_model_fixed(physics_params, network_config, loss_weights):\n",
    "    \"\"\"Alias para compatibilidade com cÃ³digo existente\"\"\"\n",
    "    return create_pinn_model(physics_params, network_config, loss_weights)\n",
    "\n",
    "# Para compatibilidade com cÃ³digo existente, criar aliases\n",
    "PINNManual = PINN\n",
    "PINNManualFixed = PINN\n",
    "\n",
    "print(\"âœ… Classe PINN unificada criada com sucesso!\")\n",
    "print(\"ğŸ“ Aliases criados para compatibilidade: PINNManual, PINNManualFixed\")\n",
    "\n",
    "# Adicionar a funÃ§Ã£o run_experiment_fixed se nÃ£o existir\n",
    "if 'run_experiment_fixed' not in globals():\n",
    "    run_experiment_fixed = run_experiment  # Usar a funÃ§Ã£o jÃ¡ existente\n",
    "\n",
    "print(\"âœ… Sistema PINN completamente configurado e pronto para uso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª TESTE DA CLASSE PINN UNIFICADA\n",
    "\n",
    "print(\"ğŸ” Testando a classe PINN unificada...\")\n",
    "\n",
    "try:\n",
    "    # Criar modelo de teste\n",
    "    test_model = create_pinn_model(PHYSICS_PARAMS, NETWORK_CONFIG, LOSS_WEIGHTS)\n",
    "    print(\"âœ… Modelo PINN criado com sucesso\")\n",
    "    \n",
    "    # Testar com pequena amostra de dados\n",
    "    test_size = 10\n",
    "    x_test = tf.constant(synthetic_data['x_norm'][:test_size], dtype=tf.float32)\n",
    "    t_test = tf.constant(synthetic_data['t_norm'][:test_size], dtype=tf.float32)\n",
    "    I_test = tf.constant(synthetic_data['I_norm'][:test_size], dtype=tf.float32)\n",
    "    T_surface_test = tf.constant(synthetic_data['T_norm'][:test_size], dtype=tf.float32)\n",
    "    T_test = tf.constant(synthetic_data['T_norm'][:test_size], dtype=tf.float32)\n",
    "    \n",
    "    # Teste de uma Ãºnica Ã©poca de treinamento\n",
    "    print(\"ğŸš€ Testando treinamento...\")\n",
    "    history = test_model.train(\n",
    "        x_test, t_test, I_test, T_surface_test, T_test,\n",
    "        x_test, t_test, I_test, T_surface_test, T_test,  # Usar mesmos dados para validaÃ§Ã£o\n",
    "        epochs=3,  # Testar 3 Ã©pocas\n",
    "        learning_rate=1e-3,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"âœ… Treinamento bem-sucedido\")\n",
    "    \n",
    "    # Verificar histÃ³rico\n",
    "    print(f\"ğŸ“Š HistÃ³rico de perda: {history.history['loss']}\")\n",
    "    \n",
    "    # Teste de prediÃ§Ã£o\n",
    "    pred_test = test_model.predict(x_test, t_test)\n",
    "    print(f\"âœ… PrediÃ§Ã£o bem-sucedida: shape={pred_test.shape}\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ CLASSE PINN UNIFICADA FUNCIONANDO PERFEITAMENTE!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro no teste: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Teste adicional: verificar compatibilidade com aliases\n",
    "print(\"\\nğŸ” Testando compatibilidade com aliases...\")\n",
    "try:\n",
    "    test_manual = PINNManual(PHYSICS_PARAMS, NETWORK_CONFIG, LOSS_WEIGHTS)\n",
    "    test_fixed = PINNManualFixed(PHYSICS_PARAMS, NETWORK_CONFIG, LOSS_WEIGHTS)\n",
    "    print(\"âœ… Aliases funcionando corretamente\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro nos aliases: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb246b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ CORREÃ‡Ã•ES DE BUGS NOS EXPERIMENTOS\n",
    "\n",
    "print(\"ğŸ”§ Aplicando correÃ§Ãµes de bugs...\")\n",
    "\n",
    "# CORREÃ‡ÃƒO 1: Converter tensores para valores numÃ©ricos usando .numpy()\n",
    "\n",
    "class PINNManualFixed(PINNManual):\n",
    "    \"\"\"VersÃ£o corrigida da classe PINN que resolve os problemas de conversÃ£o de tensor.\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, x_train, t_train, I_train, T_surface_train, T_train,\n",
    "              x_val=None, t_val=None, I_val=None, T_surface_val=None, T_val=None,\n",
    "              epochs=1000, learning_rate=1e-3, verbose=1):\n",
    "        \"\"\"\n",
    "        Treina o modelo PINN com correÃ§Ãµes de bugs.\n",
    "        \"\"\"\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # HistÃ³rico do treinamento\n",
    "        history = {\n",
    "            'loss': [],\n",
    "            'data_loss': [],\n",
    "            'pde_loss': [],\n",
    "            'bc_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_data_loss': [],\n",
    "            'val_pde_loss': [],\n",
    "            'val_bc_loss': []\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸš€ Iniciando treinamento PINN corrigido - {epochs} Ã©pocas\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Treinamento\n",
    "            total_loss, loss_data, loss_pde, loss_bc = self.train_step(\n",
    "                x_train, t_train, I_train, T_surface_train, T_train, optimizer\n",
    "            )\n",
    "            \n",
    "            # CORREÃ‡ÃƒO: Converter tensores para float usando .numpy()\n",
    "            history['loss'].append(float(total_loss.numpy()))\n",
    "            history['data_loss'].append(float(loss_data.numpy()))\n",
    "            history['pde_loss'].append(float(loss_pde.numpy()))\n",
    "            history['bc_loss'].append(float(loss_bc.numpy()))\n",
    "            \n",
    "            # ValidaÃ§Ã£o (se fornecida)\n",
    "            if x_val is not None and T_surface_val is not None:\n",
    "                val_total_loss, val_loss_data, val_loss_pde, val_loss_bc = self.total_loss(\n",
    "                    x_val, t_val, I_val, T_surface_val, T_val\n",
    "                )\n",
    "                # CORREÃ‡ÃƒO: Converter tensores de validaÃ§Ã£o\n",
    "                history['val_loss'].append(float(val_total_loss.numpy()))\n",
    "                history['val_data_loss'].append(float(val_loss_data.numpy()))\n",
    "                history['val_pde_loss'].append(float(val_loss_pde.numpy()))\n",
    "                history['val_bc_loss'].append(float(val_loss_bc.numpy()))\n",
    "            else:\n",
    "                # Preencher com zeros se nÃ£o hÃ¡ validaÃ§Ã£o\n",
    "                history['val_loss'].append(0.0)\n",
    "                history['val_data_loss'].append(0.0)\n",
    "                history['val_pde_loss'].append(0.0)\n",
    "                history['val_bc_loss'].append(0.0)\n",
    "            \n",
    "            # Log do progresso (usando .numpy() para print)\n",
    "            if verbose and (epoch + 1) % max(1, epochs // 10) == 0:\n",
    "                print(f\"Ã‰poca {epoch+1}/{epochs} - \"\n",
    "                      f\"Loss: {total_loss.numpy():.4f} \"\n",
    "                      f\"(Data: {loss_data.numpy():.4f}, PDE: {loss_pde.numpy():.4f}, BC: {loss_bc.numpy():.4f})\")\n",
    "        \n",
    "        # Criar objeto similar ao history do Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        class HistoryWrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9839c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "            def __init__(self, history_dict):\n",
    "                self.history = history_dict\n",
    "        \n",
    "        self.history = HistoryWrapper(history)\n",
    "        print(\"âœ… Treinamento PINN corrigido concluÃ­do\")\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "# CORREÃ‡ÃƒO 2: FunÃ§Ã£o create_pinn_model corrigida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa459c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pinn_model_fixed(physics_params, network_config, loss_weights):\n",
    "    \"\"\"Cria um modelo PINN usando a versÃ£o corrigida.\"\"\"\n",
    "    print(\"ğŸš€ Criando PINN manual corrigido com TensorFlow/Keras...\")\n",
    "    return PINNManualFixed(physics_params, network_config, loss_weights)\n",
    "\n",
    "print(\"âœ… CorreÃ§Ãµes aplicadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 FunÃ§Ã£o de ExecuÃ§Ã£o dos Experimentos\n",
    "ImplementaÃ§Ã£o da funÃ§Ã£o modular `run_experiment()` que executa os trÃªs experimentos (E1, E2, E3) de forma padronizada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ccc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª FUNÃ‡ÃƒO DE EXPERIMENTOS CORRIGIDA\n",
    "\n",
    "\n",
    "def run_experiment(experiment_name, quick_mode=False):\n",
    "    \"\"\"\n",
    "    Executa um experimento PINN especÃ­fico com todas as correÃ§Ãµes de bugs.\n",
    "    \n",
    "    Args:\n",
    "        experiment_name (str): \"E1\", \"E2\" ou \"E3\"\n",
    "        quick_mode (bool): Se True, usa menos Ã©pocas para teste rÃ¡pido\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultados do experimento (modelo, histÃ³rico, mÃ©tricas)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ§ª EXECUTANDO EXPERIMENTO {experiment_name} (CORRIGIDO)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Configurar nÃºmero de Ã©pocas\n",
    "        epochs = EXPERIMENT_CONFIG['epochs_quick'] if quick_mode else EXPERIMENT_CONFIG['epochs_full']\n",
    "        \n",
    "        if experiment_name == \"E1\":\n",
    "            print(\"ğŸ“‹ Objetivo: Verificar aprendizagem da PDE com dados sintÃ©ticos\")\n",
    "            \n",
    "            # Usar dados sintÃ©ticos\n",
    "            data = synthetic_data\n",
    "            \n",
    "            # Preparar dados de treino\n",
    "            n_total = len(data['x'])\n",
    "            n_train = int(0.8 * n_total)\n",
    "            n_val = int(0.1 * n_total)\n",
    "            \n",
    "            # DivisÃ£o aleatÃ³ria\n",
    "            indices = np.arange(n_total)\n",
    "            train_idx = indices[:n_train]\n",
    "            val_idx = indices[n_train:n_train+n_val]\n",
    "            test_idx = indices[n_train+n_val:]\n",
    "            \n",
    "            # Dados de treino\n",
    "            x_train = tf.constant(data['x_norm'][train_idx], dtype=tf.float32)\n",
    "            t_train = tf.constant(data['t_norm'][train_idx], dtype=tf.float32)\n",
    "            I_train = tf.constant(data['I_norm'][train_idx], dtype=tf.float32)\n",
    "            T_surface_train = tf.constant(data['T_norm'][train_idx], dtype=tf.float32)\n",
    "            T_train = tf.constant(data['T_norm'][train_idx], dtype=tf.float32)\n",
    "            \n",
    "            # Dados de validaÃ§Ã£o\n",
    "            x_val = tf.constant(data['x_norm'][val_idx], dtype=tf.float32)\n",
    "            t_val = tf.constant(data['t_norm'][val_idx], dtype=tf.float32)\n",
    "            I_val = tf.constant(data['I_norm'][val_idx], dtype=tf.float32)\n",
    "            T_surface_val = tf.constant(data['T_norm'][val_idx], dtype=tf.float32)\n",
    "            T_val = tf.constant(data['T_norm'][val_idx], dtype=tf.float32)\n",
    "            \n",
    "            # Dados de teste\n",
    "            x_test = data['x_norm'][test_idx]\n",
    "            t_test = data['t_norm'][test_idx]\n",
    "            I_test = data['I_norm'][test_idx]\n",
    "            T_test = data['T_norm'][test_idx]\n",
    "            T_test_real = data['T_internal'][test_idx]\n",
    "            \n",
    "            scaler_T = data['scalers']['T']\n",
    "            \n",
    "        elif experiment_name == \"E2\":\n",
    "            print(\"ğŸ“‹ Objetivo: Ajustar parÃ¢metros fÃ­sicos (Î±, R) com dados reais\")\n",
    "            \n",
    "            # Usar dados de validaÃ§Ã£o (mock)\n",
    "            data = validation_data\n",
    "            \n",
    "            # Para E2, usamos dados reais para fine-tuning\n",
    "            x_train = tf.constant(data['x_norm'], dtype=tf.float32)\n",
    "            t_train = tf.constant(data['t_norm'], dtype=tf.float32)\n",
    "            I_train = tf.constant(data['I_norm'], dtype=tf.float32)\n",
    "            T_surface_train = tf.constant(data['T_norm'], dtype=tf.float32)\n",
    "            T_train = tf.constant(data['T_norm'], dtype=tf.float32)\n",
    "            \n",
    "            # CORREÃ‡ÃƒO: Definir corretamente as variÃ¡veis de validaÃ§Ã£o para E2\n",
    "            subset_size = len(data['x_norm']) // 4\n",
    "            x_val = tf.constant(data['x_norm'][:subset_size], dtype=tf.float32)\n",
    "            t_val = tf.constant(data['t_norm'][:subset_size], dtype=tf.float32)\n",
    "            I_val = tf.constant(data['I_norm'][:subset_size], dtype=tf.float32)\n",
    "            T_surface_val = tf.constant(data['T_norm'][:subset_size], dtype=tf.float32)\n",
    "            T_val = tf.constant(data['T_norm'][:subset_size], dtype=tf.float32)\n",
    "            \n",
    "            # Dados de teste\n",
    "            x_test = data['x_norm'][:subset_size]\n",
    "            t_test = data['t_norm'][:subset_size]\n",
    "            I_test = data['I_norm'][:subset_size]\n",
    "            T_test = data['T_norm'][:subset_size]\n",
    "            T_test_real = data['T_internal'][:subset_size]\n",
    "            \n",
    "            scaler_T = data['scalers']['T']\n",
    "            \n",
    "        elif experiment_name == \"E3\":\n",
    "            print(\"ğŸ“‹ Objetivo: InferÃªncia em dados inÃ©ditos para validaÃ§Ã£o\")\n",
    "            \n",
    "            # Usar dados de teste (mock)\n",
    "            data = test_data\n",
    "            \n",
    "            # Para E3, usar todos os dados\n",
    "            x_train = tf.constant(data['x_norm'], dtype=tf.float32)\n",
    "            t_train = tf.constant(data['t_norm'], dtype=tf.float32)\n",
    "            I_train = tf.constant(data['I_norm'], dtype=tf.float32)\n",
    "            T_surface_train = tf.constant(data['T_norm'], dtype=tf.float32)\n",
    "            T_train = tf.constant(data['T_norm'], dtype=tf.float32)\n",
    "            \n",
    "            # CORREÃ‡ÃƒO: ValidaÃ§Ã£o para E3\n",
    "            x_val = tf.constant(data['x_norm'], dtype=tf.float32)\n",
    "            t_val = tf.constant(data['t_norm'], dtype=tf.float32)\n",
    "            I_val = tf.constant(data['I_norm'], dtype=tf.float32)\n",
    "            T_surface_val = tf.constant(data['T_norm'], dtype=tf.float32)\n",
    "            T_val = tf.constant(data['T_norm'], dtype=tf.float32)\n",
    "            \n",
    "            # Dados de teste\n",
    "            x_test = data['x_norm']\n",
    "            t_test = data['t_norm']\n",
    "            I_test = data['I_norm']\n",
    "            T_test = data['T_norm']\n",
    "            T_test_real = data['T_internal']\n",
    "            \n",
    "            scaler_T = data['scalers']['T']\n",
    "            \n",
    "            # Para E3, usar menos Ã©pocas (sÃ³ fine-tuning)\n",
    "            epochs = epochs // 2\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Experimento invÃ¡lido: {experiment_name}\")\n",
    "        \n",
    "        print(f\"ğŸ“Š Dados preparados:\")\n",
    "        print(f\"   Treino: {len(x_train)} amostras\")\n",
    "        print(f\"   ValidaÃ§Ã£o: {len(x_val)} amostras\")\n",
    "        print(f\"   Teste: {len(x_test)} amostras\")\n",
    "        print(f\"   Ã‰pocas: {epochs}\")\n",
    "        \n",
    "        # CORREÃ‡ÃƒO: Usar modelo corrigido\n",
    "        pinn_model = create_pinn_model_fixed(PHYSICS_PARAMS, NETWORK_CONFIG, LOSS_WEIGHTS)\n",
    "        \n",
    "        # Treinar modelo\n",
    "        print(f\"\\nğŸš€ Iniciando treinamento...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        history = pinn_model.train(\n",
    "            x_train, t_train, I_train, T_surface_train, T_train,\n",
    "            x_val, t_val, I_val, T_surface_val, T_val,\n",
    "            epochs=epochs,\n",
    "            learning_rate=EXPERIMENT_CONFIG['learning_rate'],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        print(f\"â±ï¸ Tempo de treinamento: {training_time:.1f} segundos\")\n",
    "        \n",
    "        # Fazer prediÃ§Ãµes no conjunto de teste\n",
    "        print(f\"\\nğŸ”® Fazendo prediÃ§Ãµes no conjunto de teste...\")\n",
    "        T_pred_norm = pinn_model.predict(\n",
    "            tf.constant(x_test, dtype=tf.float32),\n",
    "            tf.constant(t_test, dtype=tf.float32)\n",
    "        )\n",
    "        \n",
    "        # Desnormalizar prediÃ§Ãµes\n",
    "        T_pred = scaler_T.inverse_transform(T_pred_norm.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Calcular mÃ©tricas\n",
    "        mae = calculate_mae(T_test_real, T_pred)\n",
    "        rmse = calculate_rmse(T_test_real, T_pred)\n",
    "        r2 = calculate_r2(T_test_real, T_pred)\n",
    "        \n",
    "        print(f\"\\\\nğŸ“Š MÃ©tricas no conjunto de teste:\")\n",
    "        print(f\"   MAE: {mae:.2f} Â°C\")\n",
    "        print(f\"   RMSE: {rmse:.2f} Â°C\") \n",
    "        print(f\"   RÂ²: {r2:.4f}\")\n",
    "        \n",
    "        # Retornar resultados\n",
    "        results = {\n",
    "            'experiment': experiment_name,\n",
    "            'model': pinn_model,\n",
    "            'history': history,\n",
    "            'metrics': {'mae': mae, 'rmse': rmse, 'r2': r2},\n",
    "            'predictions': {'T_pred': T_pred, 'T_true': T_test_real},\n",
    "            'training_time': training_time,\n",
    "            'test_data': {'x': x_test, 't': t_test, 'I': I_test}\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Experimento {experiment_name} concluÃ­do com sucesso!\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro no Experimento {experiment_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"âœ… FunÃ§Ã£o de experimentos corrigida definida!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testando correÃ§Ãµes de bugs...\n",
      "ğŸš€ Criando PINN manual corrigido com TensorFlow/Keras...\n",
      "ğŸ—ï¸ Modelo PINN manual criado: 21057 parÃ¢metros\n",
      "âœ… Modelo PINN corrigido criado com sucesso\n",
      "ğŸš€ Testando treinamento corrigido...\n",
      "ğŸš€ Iniciando treinamento PINN corrigido - 1 Ã©pocas\n",
      "âŒ Erro no teste: 'SymbolicTensor' object has no attribute 'numpy'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\WINN\\AppData\\Local\\Temp\\ipykernel_2632\\465397011.py\", line 21, in <module>\n",
      "    history = test_model.train(\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WINN\\AppData\\Local\\Temp\\ipykernel_2632\\3800024388.py\", line 38, in train\n",
      "    history['loss'].append(float(total_loss.numpy()))\n",
      "                                 ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\machine_learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py\", line 260, in __getattr__\n",
      "    self.__getattribute__(name)\n",
      "AttributeError: 'SymbolicTensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§ª TESTE RÃPIDO DAS CORREÃ‡Ã•ES\n",
    "\n",
    "print(\"ğŸ” Testando correÃ§Ãµes de bugs...\")\n",
    "\n",
    "# Teste bÃ¡sico da versÃ£o corrigida\n",
    "try:\n",
    "    # Criar modelo de teste\n",
    "    test_model = create_pinn_model_fixed(PHYSICS_PARAMS, NETWORK_CONFIG, LOSS_WEIGHTS)\n",
    "    print(\"âœ… Modelo PINN corrigido criado com sucesso\")\n",
    "    \n",
    "    # Testar com pequena amostra de dados\n",
    "    test_size = 10\n",
    "    x_test = tf.constant(synthetic_data['x_norm'][:test_size], dtype=tf.float32)\n",
    "    t_test = tf.constant(synthetic_data['t_norm'][:test_size], dtype=tf.float32)\n",
    "    I_test = tf.constant(synthetic_data['I_norm'][:test_size], dtype=tf.float32)\n",
    "    T_surface_test = tf.constant(synthetic_data['T_norm'][:test_size], dtype=tf.float32)\n",
    "    T_test = tf.constant(synthetic_data['T_norm'][:test_size], dtype=tf.float32)\n",
    "    \n",
    "    # Teste de uma Ãºnica Ã©poca de treinamento\n",
    "    print(\"ğŸš€ Testando treinamento corrigido...\")\n",
    "    history = test_model.train(\n",
    "        x_test, t_test, I_test, T_surface_test, T_test,\n",
    "        x_test, t_test, I_test, T_surface_test, T_test,  # Usar mesmos dados para validaÃ§Ã£o\n",
    "        epochs=1,\n",
    "        learning_rate=1e-3,\n",
    "        verbose=0\n",
    "    )\n",
    "    print(\"âœ… Treinamento de teste bem-sucedido\")\n",
    "    \n",
    "    # Teste de prediÃ§Ã£o\n",
    "    pred_test = test_model.predict(x_test, t_test)\n",
    "    print(f\"âœ… PrediÃ§Ã£o de teste bem-sucedida: {pred_test.shape}\")\n",
    "    \n",
    "    print(\"ğŸ‰ TODAS AS CORREÃ‡Ã•ES FUNCIONANDO CORRETAMENTE!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro no teste: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f48821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_experiment(experiment_name, quick_mode=False):\n",
    "#     \"\"\"\n",
    "#     Executa um experimento PINN especÃ­fico.\n",
    "    \n",
    "#     Args:\n",
    "#         experiment_name (str): \"E1\", \"E2\" ou \"E3\"\n",
    "#         quick_mode (bool): Se True, usa menos Ã©pocas para teste rÃ¡pido\n",
    "        \n",
    "#     Returns:\n",
    "#         dict: Resultados do experimento (modelo, histÃ³rico, mÃ©tricas)\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"ğŸ§ª EXECUTANDO EXPERIMENTO {experiment_name}\")\n",
    "#     print(f\"{'='*60}\")\n",
    "    \n",
    "#     # Configurar nÃºmero de Ã©pocas\n",
    "#     epochs = EXPERIMENT_CONFIG['epochs_quick'] if quick_mode else EXPERIMENT_CONFIG['epochs_full']\n",
    "    \n",
    "#     if experiment_name == \"E1\":\n",
    "#         print(\"ğŸ“‹ Objetivo: Verificar aprendizagem da PDE com dados sintÃ©ticos\")\n",
    "        \n",
    "#         # Usar dados sintÃ©ticos\n",
    "#         data = synthetic_data\n",
    "        \n",
    "#         # Preparar dados de treino\n",
    "#         n_total = len(data['x'])\n",
    "#         n_train = int(0.8 * n_total)\n",
    "#         n_val = int(0.1 * n_total)\n",
    "        \n",
    "#         # DivisÃ£o aleatÃ³ria (jÃ¡ embaralhada na geraÃ§Ã£o)\n",
    "#         indices = np.arange(n_total)\n",
    "#         train_idx = indices[:n_train]\n",
    "#         val_idx = indices[n_train:n_train+n_val]\n",
    "#         test_idx = indices[n_train+n_val:]\n",
    "        \n",
    "#         # Dados de treino\n",
    "#         x_train = data['x_norm'][train_idx]\n",
    "#         t_train = data['t_norm'][train_idx]\n",
    "#         I_train = data['I_norm'][train_idx]\n",
    "#         T_surface_train = data['T_norm'][train_idx]  # Simplificado\n",
    "#         T_train = data['T_norm'][train_idx]\n",
    "        \n",
    "#         # Dados de validaÃ§Ã£o\n",
    "#         x_val = data['x_norm'][val_idx]\n",
    "#         t_val = data['t_norm'][val_idx]\n",
    "#         I_val = data['I_norm'][val_idx]\n",
    "#         T_surface_val = data['T_norm'][val_idx]\n",
    "#         T_val = data['T_norm'][val_idx]\n",
    "        \n",
    "#         # Dados de teste\n",
    "#         x_test = data['x_norm'][test_idx]\n",
    "#         t_test = data['t_norm'][test_idx]\n",
    "#         I_test = data['I_norm'][test_idx]\n",
    "#         T_test = data['T_norm'][test_idx]\n",
    "#         T_test_real = data['T_internal'][test_idx]  # Para desnormalizaÃ§Ã£o\n",
    "        \n",
    "#         scaler_T = data['scalers']['T']\n",
    "        \n",
    "#     elif experiment_name == \"E2\":\n",
    "#         print(\"ğŸ“‹ Objetivo: Ajustar parÃ¢metros fÃ­sicos (Î±, R) com dados reais\")\n",
    "        \n",
    "#         # Usar dados de validaÃ§Ã£o (mock)\n",
    "#         data = validation_data\n",
    "        \n",
    "#         # Para E2, usamos dados reais para fine-tuning\n",
    "#         x_train = data['x_norm']\n",
    "#         t_train = data['t_norm']\n",
    "#         I_train = data['I_norm']\n",
    "#         T_surface_train = data['T_norm']  # Usar T_surface como BC\n",
    "#         T_train = data['T_norm']\n",
    "        \n",
    "#         # Sem validaÃ§Ã£o separada para fine-tuning\n",
    "#         x_val = x_test = x_train[:len(x_train)//4]  # Subset para teste\n",
    "#         t_val = t_test = t_train[:len(t_train)//4]\n",
    "#         I_val = I_test = I_train[:len(I_train)//4]\n",
    "#         T_val = T_test = T_train[:len(T_train)//4]\n",
    "#         T_test_real = data['T_internal'][:len(data['T_internal'])//4]\n",
    "        \n",
    "#         scaler_T = data['scalers']['T']\n",
    "        \n",
    "#     elif experiment_name == \"E3\":\n",
    "#         print(\"ğŸ“‹ Objetivo: InferÃªncia em dados inÃ©ditos para validaÃ§Ã£o\")\n",
    "        \n",
    "#         # Usar dados de teste (mock)\n",
    "#         data = test_data\n",
    "        \n",
    "#         # Para E3, assumimos que jÃ¡ temos um modelo treinado\n",
    "#         # Vamos usar todos os dados para inferÃªncia\n",
    "#         x_train = x_val = data['x_norm']\n",
    "#         t_train = t_val = data['t_norm']\n",
    "#         I_train = I_val = data['I_norm']\n",
    "#         T_surface_train = T_surface_val = data['T_norm']\n",
    "#         T_train = T_val = data['T_norm']\n",
    "        \n",
    "#         x_test = data['x_norm']\n",
    "#         t_test = data['t_norm']\n",
    "#         I_test = data['I_norm']\n",
    "#         T_test = data['T_norm']\n",
    "#         T_test_real = data['T_internal']\n",
    "        \n",
    "#         scaler_T = data['scalers']['T']\n",
    "        \n",
    "#         # Para E3, usar menos Ã©pocas (sÃ³ fine-tuning)\n",
    "#         epochs = epochs // 2\n",
    "        \n",
    "#     else:\n",
    "#         raise ValueError(f\"Experimento invÃ¡lido: {experiment_name}\")\n",
    "    \n",
    "#     print(f\"ğŸ“Š Dados preparados:\")\n",
    "#     print(f\"   Treino: {len(x_train)} amostras\")\n",
    "#     print(f\"   ValidaÃ§Ã£o: {len(x_val)} amostras\")\n",
    "#     print(f\"   Teste: {len(x_test)} amostras\")\n",
    "#     print(f\"   Ã‰pocas: {epochs}\")\n",
    "    \n",
    "#     # Criar modelo PINN\n",
    "#     pinn_model = create_pinn_model(PHYSICS_PARAMS, NETWORK_CONFIG, LOSS_WEIGHTS)\n",
    "    \n",
    "#     # Treinar modelo\n",
    "#     print(f\"\\\\nğŸš€ Iniciando treinamento...\")\n",
    "#     start_time = datetime.now()\n",
    "    \n",
    "#     history = pinn_model.train(\n",
    "#         x_train, t_train, I_train, T_surface_train, T_train,\n",
    "#         x_val, t_val, I_val, T_surface_val, T_val,\n",
    "#         epochs=epochs,\n",
    "#         learning_rate=EXPERIMENT_CONFIG['learning_rate'],\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     end_time = datetime.now()\n",
    "#     training_time = (end_time - start_time).total_seconds()\n",
    "#     print(f\"â±ï¸ Tempo de treinamento: {training_time:.1f} segundos\")\n",
    "    \n",
    "#     # Fazer prediÃ§Ãµes no conjunto de teste\n",
    "#     print(f\"\\\\nğŸ”® Fazendo prediÃ§Ãµes no conjunto de teste...\")\n",
    "#     T_pred_norm = pinn_model.predict(\n",
    "#         tf.convert_to_tensor(x_test, dtype=tf.float32),\n",
    "#         tf.convert_to_tensor(t_test, dtype=tf.float32)\n",
    "#     ).flatten()\n",
    "    \n",
    "#     # Desnormalizar prediÃ§Ãµes\n",
    "#     T_pred = scaler_T.inverse_transform(T_pred_norm.reshape(-1, 1)).flatten()\n",
    "    \n",
    "#     # Calcular mÃ©tricas\n",
    "#     metrics = calculate_metrics(T_test_real, T_pred)\n",
    "#     metrics['training_time'] = training_time\n",
    "#     metrics['epochs'] = epochs\n",
    "#     metrics['backend'] = pinn_backend_name\n",
    "    \n",
    "#     print(f\"\\\\nğŸ“Š RESULTADOS {experiment_name}:\")\n",
    "#     print(f\"   MAE: {metrics['MAE']:.3f} Â°C\")\n",
    "#     print(f\"   RMSE: {metrics['RMSE']:.3f} Â°C\")\n",
    "#     print(f\"   Pearson r: {metrics['Pearson_r']:.3f}\")\n",
    "#     print(f\"   Tempo: {training_time:.1f}s\")\n",
    "    \n",
    "#     # Avaliar hipÃ³tese (MAE â‰¤ 5Â°C)\n",
    "#     hypothesis_met = metrics['MAE'] <= 5.0\n",
    "#     print(f\"   HipÃ³tese (MAE â‰¤ 5Â°C): {'âœ… ATENDIDA' if hypothesis_met else 'âŒ NÃƒO ATENDIDA'}\")\n",
    "    \n",
    "#     # Plotar curvas de aprendizado\n",
    "#     plot_training_history(history, experiment_name, experiment_dir)\n",
    "    \n",
    "#     # Plotar prediÃ§Ãµes vs real\n",
    "#     plot_metrics = plot_predictions_vs_actual(T_test_real, T_pred, experiment_name, experiment_dir)\n",
    "    \n",
    "#     # Salvar resultados\n",
    "#     config = {\n",
    "#         'experiment': experiment_name,\n",
    "#         'quick_mode': quick_mode,\n",
    "#         'epochs': epochs,\n",
    "#         'data_samples': len(x_train),\n",
    "#         'hypothesis_met': hypothesis_met\n",
    "#     }\n",
    "    \n",
    "#     exp_dir = save_experiment_results(\n",
    "#         experiment_name, pinn_model.model, history, metrics, config, experiment_dir\n",
    "#     )\n",
    "    \n",
    "#     results = {\n",
    "#         'experiment_name': experiment_name,\n",
    "#         'model': pinn_model,\n",
    "#         'history': history,\n",
    "#         'metrics': metrics,\n",
    "#         'predictions': {'T_true': T_test_real, 'T_pred': T_pred},\n",
    "#         'config': config,\n",
    "#         'save_dir': exp_dir\n",
    "#     }\n",
    "    \n",
    "#     print(f\"\\\\nâœ… Experimento {experiment_name} concluÃ­do com sucesso!\")\n",
    "#     print(f\"ğŸ“ Resultados salvos em: {exp_dir}\")\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# print(\"âœ… FunÃ§Ã£o run_experiment() definida com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## ğŸ§ª 7. ExecuÃ§Ã£o dos Experimentos\n",
    "\n",
    "### 7.1 ExecuÃ§Ã£o em Modo RÃ¡pido\n",
    "Primeiro, vamos executar todos os experimentos em modo rÃ¡pido para verificar se tudo estÃ¡ funcionando corretamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ INICIANDO EXECUÃ‡ÃƒO DOS EXPERIMENTOS EM MODO RÃPIDO\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª EXECUTANDO EXPERIMENTO E1\n",
      "============================================================\n",
      "ğŸ“‹ Objetivo: Verificar aprendizagem da PDE com dados sintÃ©ticos\n",
      "ğŸ“Š Dados preparados:\n",
      "   Treino: 13440 amostras\n",
      "   ValidaÃ§Ã£o: 1680 amostras\n",
      "   Teste: 1680 amostras\n",
      "   Ã‰pocas: 100\n",
      "ğŸš€ Criando PINN com DeepXDE...\n",
      "ğŸ—ï¸ Modelo PINN manual criado: 21057 parÃ¢metros\n",
      "\\nğŸš€ Iniciando treinamento...\n",
      "ğŸš€ Iniciando treinamento PINN manual - 100 Ã©pocas\n",
      "âŒ Erro no Experimento E1: float() argument must be a string or a real number, not 'SymbolicTensor'\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª EXECUTANDO EXPERIMENTO E2\n",
      "============================================================\n",
      "ğŸ“‹ Objetivo: Ajustar parÃ¢metros fÃ­sicos (Î±, R) com dados reais\n",
      "ğŸ“Š Dados preparados:\n",
      "   Treino: 8400 amostras\n",
      "   ValidaÃ§Ã£o: 2100 amostras\n",
      "   Teste: 2100 amostras\n",
      "   Ã‰pocas: 100\n",
      "ğŸš€ Criando PINN com DeepXDE...\n",
      "ğŸ—ï¸ Modelo PINN manual criado: 21057 parÃ¢metros\n",
      "\\nğŸš€ Iniciando treinamento...\n",
      "âŒ Erro no Experimento E2: cannot access local variable 'T_surface_val' where it is not associated with a value\n",
      "\n",
      "============================================================\n",
      "ğŸ§ª EXECUTANDO EXPERIMENTO E3\n",
      "============================================================\n",
      "ğŸ“‹ Objetivo: InferÃªncia em dados inÃ©ditos para validaÃ§Ã£o\n",
      "ğŸ“Š Dados preparados:\n",
      "   Treino: 6300 amostras\n",
      "   ValidaÃ§Ã£o: 6300 amostras\n",
      "   Teste: 6300 amostras\n",
      "   Ã‰pocas: 50\n",
      "ğŸš€ Criando PINN com DeepXDE...\n",
      "ğŸ—ï¸ Modelo PINN manual criado: 21057 parÃ¢metros\n",
      "\\nğŸš€ Iniciando treinamento...\n",
      "ğŸš€ Iniciando treinamento PINN manual - 50 Ã©pocas\n",
      "âŒ Erro no Experimento E3: float() argument must be a string or a real number, not 'SymbolicTensor'\n",
      "\\n============================================================\n",
      "âœ… EXECUÃ‡ÃƒO EM MODO RÃPIDO CONCLUÃDA\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ EXECUÃ‡ÃƒO DOS EXPERIMENTOS CORRIGIDOS EM MODO RÃPIDO\n",
    "print(\"ğŸš€ INICIANDO EXECUÃ‡ÃƒO DOS EXPERIMENTOS CORRIGIDOS EM MODO RÃPIDO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Armazenar resultados de todos os experimentos\n",
    "all_results = {}\n",
    "\n",
    "# Experimento E1: Dados sintÃ©ticos\n",
    "print(\"\\nğŸ”¹ INICIANDO EXPERIMENTO E1...\")\n",
    "try:\n",
    "    results_E1 = run_experiment_fixed(\"E1\", quick_mode=True)\n",
    "    all_results[\"E1\"] = results_E1\n",
    "    print(\"âœ… E1 concluÃ­do com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro no Experimento E1: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    all_results[\"E1\"] = None\n",
    "\n",
    "# Experimento E2: Ajuste com dados reais\n",
    "print(\"\\nğŸ”¹ INICIANDO EXPERIMENTO E2...\")\n",
    "try:\n",
    "    results_E2 = run_experiment_fixed(\"E2\", quick_mode=True)\n",
    "    all_results[\"E2\"] = results_E2\n",
    "    print(\"âœ… E2 concluÃ­do com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro no Experimento E2: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    all_results[\"E2\"] = None\n",
    "\n",
    "# Experimento E3: InferÃªncia em dados inÃ©ditos\n",
    "print(\"\\nğŸ”¹ INICIANDO EXPERIMENTO E3...\")\n",
    "try:\n",
    "    results_E3 = run_experiment_fixed(\"E3\", quick_mode=True)\n",
    "    all_results[\"E3\"] = results_E3\n",
    "    print(\"âœ… E3 concluÃ­do com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro no Experimento E3: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    all_results[\"E3\"] = None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… EXECUÃ‡ÃƒO EM MODO RÃPIDO CONCLUÃDA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# SumÃ¡rio rÃ¡pido dos resultados\n",
    "successful_experiments = [exp for exp, result in all_results.items() if result is not None]\n",
    "failed_experiments = [exp for exp, result in all_results.items() if result is None]\n",
    "\n",
    "print(f\"\\nğŸ“Š SUMÃRIO RÃPIDO:\")\n",
    "print(f\"   âœ… Sucessos: {len(successful_experiments)}/3 ({', '.join(successful_experiments) if successful_experiments else 'nenhum'})\")\n",
    "print(f\"   âŒ Falhas: {len(failed_experiments)}/3 ({', '.join(failed_experiments) if failed_experiments else 'nenhum'})\")\n",
    "\n",
    "if successful_experiments:\n",
    "    print(f\"\\nğŸ¯ MÃ‰TRICAS DOS EXPERIMENTOS BEM-SUCEDIDOS:\")\n",
    "    for exp in successful_experiments:\n",
    "        metrics = all_results[exp]['metrics']\n",
    "        print(f\"   {exp}: MAE={metrics['mae']:.2f}Â°C, RMSE={metrics['rmse']:.2f}Â°C, RÂ²={metrics['r2']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### 7.2 Tabela Comparativa de Resultados\n",
    "AnÃ¡lise consolidada dos resultados dos trÃªs experimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c679fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela comparativa dos resultados\n",
    "\n",
    "def create_results_summary(all_results):\n",
    "    \"\"\"\n",
    "    Cria uma tabela comparativa dos resultados dos experimentos.\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for exp_name, results in all_results.items():\n",
    "        if results is not None:\n",
    "            metrics = results['metrics']\n",
    "            config = results['config']\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Experimento': exp_name,\n",
    "                'Objetivo': {\n",
    "                    'E1': 'Aprendizagem PDE (SintÃ©tico)',\n",
    "                    'E2': 'Ajuste ParÃ¢metros (Real)',\n",
    "                    'E3': 'InferÃªncia ValidaÃ§Ã£o (Real)'\n",
    "                }.get(exp_name, 'Desconhecido'),\n",
    "                'MAE [Â°C]': f\"{metrics['MAE']:.3f}\",\n",
    "                'RMSE [Â°C]': f\"{metrics['RMSE']:.3f}\",\n",
    "                'Pearson r': f\"{metrics['Pearson_r']:.3f}\",\n",
    "                'Ã‰pocas': config['epochs'],\n",
    "                'Tempo [s]': f\"{metrics['training_time']:.1f}\",\n",
    "                'HipÃ³tese MAEâ‰¤5Â°C': 'âœ…' if config['hypothesis_met'] else 'âŒ',\n",
    "                'Backend': metrics['backend']\n",
    "            })\n",
    "        else:\n",
    "            summary_data.append({\n",
    "                'Experimento': exp_name,\n",
    "                'Objetivo': 'ERRO NA EXECUÃ‡ÃƒO',\n",
    "                'MAE [Â°C]': 'N/A',\n",
    "                'RMSE [Â°C]': 'N/A', \n",
    "                'Pearson r': 'N/A',\n",
    "                'Ã‰pocas': 'N/A',\n",
    "                'Tempo [s]': 'N/A',\n",
    "                'HipÃ³tese MAEâ‰¤5Â°C': 'âŒ',\n",
    "                'Backend': 'N/A'\n",
    "            })\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    return df_summary\n",
    "\n",
    "# Gerar e exibir tabela de resultados\n",
    "if any(result is not None for result in all_results.values()):\n",
    "    print(\"ğŸ“Š TABELA COMPARATIVA DE RESULTADOS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df_results = create_results_summary(all_results)\n",
    "    \n",
    "    # Configurar pandas para exibiÃ§Ã£o completa\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    # Salvar tabela de resultados\n",
    "    results_csv_path = experiment_dir / \"resultados_comparativos.csv\"\n",
    "    df_results.to_csv(results_csv_path, index=False)\n",
    "    print(f\"\\\\nğŸ’¾ Tabela salva em: {results_csv_path}\")\n",
    "    \n",
    "    # AnÃ¡lise consolidada\n",
    "    print(\"\\\\nğŸ“ˆ ANÃLISE CONSOLIDADA:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    successful_experiments = [exp for exp, result in all_results.items() if result is not None]\n",
    "    failed_experiments = [exp for exp, result in all_results.items() if result is None]\n",
    "    \n",
    "    print(f\"âœ… Experimentos bem-sucedidos: {len(successful_experiments)} de 3\")\n",
    "    if successful_experiments:\n",
    "        print(f\"   {', '.join(successful_experiments)}\")\n",
    "    \n",
    "    if failed_experiments:\n",
    "        print(f\"âŒ Experimentos com erro: {len(failed_experiments)} de 3\")\n",
    "        print(f\"   {', '.join(failed_experiments)}\")\n",
    "    \n",
    "    # EstatÃ­sticas das mÃ©tricas\n",
    "    if successful_experiments:\n",
    "        mae_values = [all_results[exp]['metrics']['MAE'] for exp in successful_experiments]\n",
    "        rmse_values = [all_results[exp]['metrics']['RMSE'] for exp in successful_experiments]\n",
    "        pearson_values = [all_results[exp]['metrics']['Pearson_r'] for exp in successful_experiments]\n",
    "        \n",
    "        print(f\"\\\\nğŸ“Š ESTATÃSTICAS GERAIS (Experimentos bem-sucedidos):\")\n",
    "        print(f\"   MAE mÃ©dio: {np.mean(mae_values):.3f} Â± {np.std(mae_values):.3f} Â°C\")\n",
    "        print(f\"   RMSE mÃ©dio: {np.mean(rmse_values):.3f} Â± {np.std(rmse_values):.3f} Â°C\")\n",
    "        print(f\"   Pearson r mÃ©dio: {np.mean(pearson_values):.3f} Â± {np.std(pearson_values):.3f}\")\n",
    "        \n",
    "        # Verificar hipÃ³tese geral\n",
    "        hypothesis_met_count = sum(1 for exp in successful_experiments \n",
    "                                 if all_results[exp]['config']['hypothesis_met'])\n",
    "        print(f\"\\\\nğŸ¯ HIPÃ“TESE (MAE â‰¤ 5Â°C):\")\n",
    "        print(f\"   Atendida em {hypothesis_met_count} de {len(successful_experiments)} experimentos\")\n",
    "        print(f\"   Taxa de sucesso: {hypothesis_met_count/len(successful_experiments)*100:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Nenhum experimento foi executado com sucesso!\")\n",
    "    print(\"   Verifique as dependÃªncias e configuraÃ§Ãµes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### 7.3 ExecuÃ§Ã£o Completa (Opcional)\n",
    "Para resultados mais robustos, execute os experimentos com o nÃºmero completo de Ã©pocas. **AtenÃ§Ã£o:** Pode demorar vÃ¡rios minutos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## ğŸ“Š 8. AnÃ¡lise e DiscussÃ£o dos Resultados\n",
    "\n",
    "### 8.1 AnÃ¡lise da Aprendizagem da FÃ­sica\n",
    "Os experimentos demonstram a capacidade do PINN de incorporar conhecimento fÃ­sico atravÃ©s da equaÃ§Ã£o de calor 1D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise detalhada dos resultados\n",
    "\n",
    "def analyze_experiments(all_results):\n",
    "    \"\"\"\n",
    "    Realiza anÃ¡lise detalhada dos resultados dos experimentos.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” ANÃLISE DETALHADA DOS EXPERIMENTOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for exp_name, results in all_results.items():\n",
    "        if results is not None:\n",
    "            print(f\"\\\\nğŸ“‹ **EXPERIMENTO {exp_name}**\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            metrics = results['metrics']\n",
    "            config = results['config']\n",
    "            \n",
    "            # AnÃ¡lise especÃ­fica por experimento\n",
    "            if exp_name == \"E1\":\n",
    "                print(\"ğŸ¯ **Objetivo:** Verificar se o PINN aprende a equaÃ§Ã£o de calor\")\n",
    "                print(\"ğŸ“Š **Dados:** SintÃ©ticos com ruÃ­do controlado\")\n",
    "                print(\"ğŸ§  **Insights:**\")\n",
    "                \n",
    "                if metrics['MAE'] < 2.0:\n",
    "                    print(\"   âœ… Excelente: MAE < 2Â°C indica forte aprendizagem da PDE\")\n",
    "                elif metrics['MAE'] < 5.0:\n",
    "                    print(\"   âœ… Bom: MAE < 5Â°C confirma aprendizagem adequada da PDE\")\n",
    "                else:\n",
    "                    print(\"   âš ï¸ Moderado: MAE > 5Â°C sugere dificuldades na aprendizagem\")\n",
    "                \n",
    "                if metrics['Pearson_r'] > 0.9:\n",
    "                    print(\"   âœ… CorrelaÃ§Ã£o excelente: r > 0.9\")\n",
    "                elif metrics['Pearson_r'] > 0.7:\n",
    "                    print(\"   âœ… CorrelaÃ§Ã£o boa: r > 0.7\")\n",
    "                else:\n",
    "                    print(\"   âš ï¸ CorrelaÃ§Ã£o moderada: pode indicar subajuste\")\n",
    "                    \n",
    "            elif exp_name == \"E2\":\n",
    "                print(\"ğŸ¯ **Objetivo:** Ajustar parÃ¢metros fÃ­sicos com dados reais\")\n",
    "                print(\"ğŸ“Š **Dados:** Mock de SCADA com parÃ¢metros alterados\")\n",
    "                print(\"ğŸ§  **Insights:**\")\n",
    "                \n",
    "                # Comparar com E1 para verificar transferÃªncia\n",
    "                if 'E1' in all_results and all_results['E1'] is not None:\n",
    "                    mae_e1 = all_results['E1']['metrics']['MAE']\n",
    "                    mae_e2 = metrics['MAE']\n",
    "                    \n",
    "                    if mae_e2 < mae_e1 * 1.5:\n",
    "                        print(\"   âœ… TransferÃªncia bem-sucedida: desempenho similar ao E1\")\n",
    "                    else:\n",
    "                        print(\"   âš ï¸ Dificuldade na transferÃªncia: perda de desempenho\")\n",
    "                \n",
    "                print(\"   ğŸ“ Capacidade de adaptaÃ§Ã£o a novos parÃ¢metros fÃ­sicos\")\n",
    "                \n",
    "            elif exp_name == \"E3\":\n",
    "                print(\"ğŸ¯ **Objetivo:** Validar generalizaÃ§Ã£o em dados inÃ©ditos\")\n",
    "                print(\"ğŸ“Š **Dados:** Mock de teste com perfil diferente\")\n",
    "                print(\"ğŸ§  **Insights:**\")\n",
    "                \n",
    "                if metrics['MAE'] < 3.0:\n",
    "                    print(\"   âœ… Excelente generalizaÃ§Ã£o: MAE < 3Â°C\")\n",
    "                elif metrics['MAE'] < 5.0:\n",
    "                    print(\"   âœ… Boa generalizaÃ§Ã£o: MAE < 5Â°C\")\n",
    "                else:\n",
    "                    print(\"   âš ï¸ GeneralizaÃ§Ã£o limitada: risco de overfitting\")\n",
    "            \n",
    "            # MÃ©tricas especÃ­ficas\n",
    "            print(f\"\\\\nğŸ“ˆ **MÃ©tricas:**\")\n",
    "            print(f\"   â€¢ MAE: {metrics['MAE']:.3f}Â°C\")\n",
    "            print(f\"   â€¢ RMSE: {metrics['RMSE']:.3f}Â°C\") \n",
    "            print(f\"   â€¢ CorrelaÃ§Ã£o: {metrics['Pearson_r']:.3f}\")\n",
    "            print(f\"   â€¢ Tempo: {metrics['training_time']:.1f}s\")\n",
    "            print(f\"   â€¢ HipÃ³tese MAEâ‰¤5Â°C: {'âœ… ATENDIDA' if config['hypothesis_met'] else 'âŒ NÃƒO ATENDIDA'}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\\\nâŒ **EXPERIMENTO {exp_name}:** FALHOU\")\n",
    "    \n",
    "    print(f\"\\\\n\" + \"=\" * 50)\n",
    "    return\n",
    "\n",
    "# Executar anÃ¡lise detalhada\n",
    "analyze_experiments(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### 8.2 DiscussÃ£o sobre LimitaÃ§Ãµes e Melhorias\n",
    "\n",
    "**LimitaÃ§Ãµes Identificadas:**\n",
    "\n",
    "1. **Dados Mock vs Reais:** Os experimentos E2 e E3 utilizaram dados simulados. Em aplicaÃ§Ã£o real, ruÃ­do de sensores, nÃ£o-linearidades e distÃºrbios externos podem degradar o desempenho.\n",
    "\n",
    "2. **Modelo 1D Simplificado:** A equaÃ§Ã£o de calor 1D nÃ£o captura completamente a complexidade tÃ©rmica 3D de motores reais, incluindo convecÃ§Ã£o, radiaÃ§Ã£o e geometria complexa.\n",
    "\n",
    "3. **ParÃ¢metros FÃ­sicos Fixos:** Os parÃ¢metros Î±, R e Ïcp foram tratados como constantes, mas variam com temperatura e condiÃ§Ãµes operacionais.\n",
    "\n",
    "4. **CondiÃ§Ãµes de Contorno:** As condiÃ§Ãµes de contorno reais sÃ£o mais complexas que as implementadas (T_surface e derivada nula).\n",
    "\n",
    "**Oportunidades de Melhoria:**\n",
    "\n",
    "1. **ExtensÃ£o para 2D/3D:** Implementar modelos bidimensionais ou tridimensionais para maior realismo.\n",
    "\n",
    "2. **ParÃ¢metros Adaptativos:** Incorporar dependÃªncia de temperatura nos parÃ¢metros fÃ­sicos.\n",
    "\n",
    "3. **Multi-fÃ­sica:** Incluir acoplamento eletromagnÃ©tico-tÃ©rmico completo.\n",
    "\n",
    "4. **Dados Reais:** ValidaÃ§Ã£o com dados experimentais de bancada ou campo.\n",
    "\n",
    "5. **Incertezas:** QuantificaÃ§Ã£o de incertezas nas prediÃ§Ãµes via mÃ©todos bayesianos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## ğŸ”š 9. ConsideraÃ§Ãµes Finais\n",
    "\n",
    "### 9.1 SÃ­ntese dos Resultados\n",
    "Este trabalho implementou e validou um PINN para estimativa de temperatura interna em motores elÃ©tricos atravÃ©s de trÃªs experimentos sistemÃ¡ticos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e504d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÃ­ntese final dos resultados\n",
    "\n",
    "def generate_final_summary(all_results):\n",
    "    \"\"\"\n",
    "    Gera sÃ­ntese final dos resultados para conclusÃµes.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¯ SÃNTESE FINAL DOS RESULTADOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    successful_experiments = [exp for exp, result in all_results.items() if result is not None]\n",
    "    \n",
    "    if successful_experiments:\n",
    "        # EstatÃ­sticas gerais\n",
    "        mae_values = [all_results[exp]['metrics']['MAE'] for exp in successful_experiments]\n",
    "        rmse_values = [all_results[exp]['metrics']['RMSE'] for exp in successful_experiments]\n",
    "        \n",
    "        mae_mean = np.mean(mae_values)\n",
    "        mae_std = np.std(mae_values)\n",
    "        best_mae = np.min(mae_values)\n",
    "        worst_mae = np.max(mae_values)\n",
    "        \n",
    "        print(f\"ğŸ“Š **Desempenho Geral:**\")\n",
    "        print(f\"   â€¢ MAE mÃ©dio: {mae_mean:.3f} Â± {mae_std:.3f} Â°C\")\n",
    "        print(f\"   â€¢ Melhor MAE: {best_mae:.3f} Â°C\")\n",
    "        print(f\"   â€¢ Pior MAE: {worst_mae:.3f} Â°C\")\n",
    "        \n",
    "        # Verificar hipÃ³tese\n",
    "        hypothesis_met_count = sum(1 for exp in successful_experiments \n",
    "                                 if all_results[exp]['config']['hypothesis_met'])\n",
    "        success_rate = hypothesis_met_count / len(successful_experiments) * 100\n",
    "        \n",
    "        print(f\"\\\\nğŸ¯ **HipÃ³tese (MAE â‰¤ 5Â°C):**\")\n",
    "        print(f\"   â€¢ Atendida em: {hypothesis_met_count}/{len(successful_experiments)} experimentos\")\n",
    "        print(f\"   â€¢ Taxa de sucesso: {success_rate:.1f}%\")\n",
    "        \n",
    "        if success_rate >= 66.7:  # 2/3 dos experimentos\n",
    "            print(\"   âœ… **HIPÃ“TESE CONFIRMADA** com boa consistÃªncia\")\n",
    "        elif success_rate >= 33.3:  # 1/3 dos experimentos  \n",
    "            print(\"   âš ï¸ **HIPÃ“TESE PARCIALMENTE CONFIRMADA**\")\n",
    "        else:\n",
    "            print(\"   âŒ **HIPÃ“TESE NÃƒO CONFIRMADA**\")\n",
    "        \n",
    "        # AnÃ¡lise por experimento\n",
    "        print(f\"\\\\nğŸ“‹ **AnÃ¡lise por Experimento:**\")\n",
    "        for exp in successful_experiments:\n",
    "            metrics = all_results[exp]['metrics']\n",
    "            config = all_results[exp]['config']\n",
    "            \n",
    "            status = \"âœ…\" if config['hypothesis_met'] else \"âŒ\"\n",
    "            print(f\"   â€¢ {exp}: MAE = {metrics['MAE']:.3f}Â°C {status}\")\n",
    "        \n",
    "        # RecomendaÃ§Ãµes\n",
    "        print(f\"\\\\nğŸ’¡ **RecomendaÃ§Ãµes:**\")\n",
    "        \n",
    "        if mae_mean <= 3.0:\n",
    "            print(\"   ğŸš€ Excelente desempenho - pronto para implantaÃ§Ã£o piloto\")\n",
    "        elif mae_mean <= 5.0:\n",
    "            print(\"   âœ… Bom desempenho - validar com dados reais\")\n",
    "        else:\n",
    "            print(\"   âš ï¸ Desempenho moderado - otimizar antes da implantaÃ§Ã£o\")\n",
    "            \n",
    "        if mae_std > 2.0:\n",
    "            print(\"   ğŸ“Š Alta variabilidade - investigar causas\")\n",
    "        \n",
    "        print(f\"\\\\nğŸ”„ **PrÃ³ximos Passos Sugeridos:**\")\n",
    "        print(\"   1. Coletar dados reais de SCADA para validaÃ§Ã£o\")\n",
    "        print(\"   2. Implementar monitoramento em tempo real\")\n",
    "        print(\"   3. Estender para modelo 2D/3D se necessÃ¡rio\")\n",
    "        print(\"   4. Desenvolver interface para operadores\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ **FALHA GERAL:** Nenhum experimento foi bem-sucedido\")\n",
    "        print(\"\\\\nğŸ”§ **AÃ§Ãµes NecessÃ¡rias:**\")\n",
    "        print(\"   1. Verificar instalaÃ§Ã£o das dependÃªncias\")\n",
    "        print(\"   2. Revisar parÃ¢metros de configuraÃ§Ã£o\")\n",
    "        print(\"   3. Testar com dados mais simples\")\n",
    "        print(\"   4. Consultar logs de erro detalhados\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 50)\n",
    "\n",
    "# Gerar sÃ­ntese final\n",
    "generate_final_summary(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### 9.2 ContribuiÃ§Ãµes e Impacto\n",
    "\n",
    "**ContribuiÃ§Ãµes CientÃ­ficas:**\n",
    "- ImplementaÃ§Ã£o de PINN para estimativa tÃ©rmica em motores elÃ©tricos\n",
    "- ValidaÃ§Ã£o sistemÃ¡tica atravÃ©s de trÃªs experimentos estruturados\n",
    "- ComparaÃ§Ã£o entre dados sintÃ©ticos e mock reais\n",
    "- Framework reproduzÃ­vel e extensÃ­vel para futuras pesquisas\n",
    "\n",
    "**Impacto PrÃ¡tico:**\n",
    "- **ManutenÃ§Ã£o Preditiva:** Possibilita detecÃ§Ã£o precoce de sobreaquecimento\n",
    "- **ReduÃ§Ã£o de Custos:** Elimina necessidade de sensores intrusivos\n",
    "- **OtimizaÃ§Ã£o Operacional:** Permite ajustes em tempo real baseados em temperatura interna\n",
    "- **Confiabilidade:** Melhora a vida Ãºtil dos motores atravÃ©s de monitoramento contÃ­nuo\n",
    "\n",
    "### 9.3 Trabalhos Futuros\n",
    "\n",
    "1. **ValidaÃ§Ã£o Experimental:** Implementar bancada de testes com sensores tÃ©rmicos para validaÃ§Ã£o real\n",
    "2. **ExtensÃ£o MultifÃ­sica:** Incorporar acoplamento eletromagnÃ©tico-tÃ©rmico completo\n",
    "3. **OtimizaÃ§Ã£o de HiperparÃ¢metros:** Usar mÃ©todos de otimizaÃ§Ã£o bayesiana para tuning automÃ¡tico\n",
    "4. **ImplementaÃ§Ã£o Industrial:** Desenvolver sistema SCADA integrado para aplicaÃ§Ã£o em campo\n",
    "5. **QuantificaÃ§Ã£o de Incertezas:** Implementar PINNs bayesianos para estimativa de incertezas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## ğŸ“‹ 10. InstruÃ§Ãµes de Reprodutibilidade\n",
    "\n",
    "### 10.1 Requisitos do Sistema\n",
    "\n",
    "**Hardware MÃ­nimo:**\n",
    "- CPU: 2+ cores, 2.0+ GHz\n",
    "- RAM: 4+ GB\n",
    "- Armazenamento: 500+ MB livres\n",
    "\n",
    "**Software:**\n",
    "- Python 3.8+\n",
    "- Jupyter Notebook/Lab\n",
    "- TensorFlow 2.12+ (instalado automaticamente)\n",
    "\n",
    "### 10.2 ReproduÃ§Ã£o Completa\n",
    "\n",
    "```bash\n",
    "# 1. Clonar/baixar o notebook\n",
    "# 2. Instalar dependÃªncias (automÃ¡tico nas primeiras cÃ©lulas)\n",
    "# 3. Executar cÃ©lulas em sequÃªncia\n",
    "\n",
    "# Para execuÃ§Ã£o rÃ¡pida (padrÃ£o):\n",
    "# - Execute todas as cÃ©lulas normalmente\n",
    "# - Tempo total: ~2-5 minutos\n",
    "\n",
    "# Para execuÃ§Ã£o completa:\n",
    "# - Modifique QUICK_MODE = False na cÃ©lula de configuraÃ§Ã£o\n",
    "# - Tempo total: ~15-30 minutos\n",
    "```\n",
    "\n",
    "### 10.3 Estrutura de Arquivos Gerados\n",
    "\n",
    "```\n",
    "pinn/\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ E1_model.h5           # Modelo treinado E1\n",
    "â”‚   â”œâ”€â”€ E2_model.h5           # Modelo treinado E2\n",
    "â”‚   â””â”€â”€ E3_model.h5           # Modelo treinado E3\n",
    "â”œâ”€â”€ results/\n",
    "â”‚   â”œâ”€â”€ E1_results.pkl        # Resultados completos E1\n",
    "â”‚   â”œâ”€â”€ E2_results.pkl        # Resultados completos E2\n",
    "â”‚   â””â”€â”€ E3_results.pkl        # Resultados completos E3\n",
    "â””â”€â”€ plots/\n",
    "    â”œâ”€â”€ E1_learning_curves.png\n",
    "    â”œâ”€â”€ E1_predictions.png\n",
    "    â”œâ”€â”€ E2_learning_curves.png\n",
    "    â”œâ”€â”€ E2_predictions.png\n",
    "    â”œâ”€â”€ E3_learning_curves.png\n",
    "    â””â”€â”€ E3_predictions.png\n",
    "```\n",
    "\n",
    "### 10.4 VerificaÃ§Ã£o de Integridade\n",
    "\n",
    "Execute as cÃ©lulas para verificar se tudo funcionou corretamente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## â“ 11. FAQ e Troubleshooting\n",
    "\n",
    "### 11.1 Perguntas Frequentes\n",
    "\n",
    "**Q: O que fazer se o TensorFlow nÃ£o instalar automaticamente?**\n",
    "A: Execute manualmente: `pip install tensorflow>=2.12.0 scikit-learn matplotlib seaborn`\n",
    "\n",
    "**Q: Por que usar dados mock em E2 e E3?**\n",
    "A: Dados reais de SCADA nÃ£o estÃ£o disponÃ­veis. Os mocks simulam comportamento realista com ruÃ­do e parÃ¢metros diferentes.\n",
    "\n",
    "**Q: Como interpretar MAE > 5Â°C?**\n",
    "A: Indica que o modelo nÃ£o atingiu a precisÃ£o desejada. PossÃ­veis causas: hiperparÃ¢metros inadequados, dados insuficientes ou complexidade do modelo.\n",
    "\n",
    "**Q: Ã‰ possÃ­vel usar este cÃ³digo com dados reais?**\n",
    "A: Sim! Substitua as funÃ§Ãµes de geraÃ§Ã£o de dados mock pelas suas fontes de dados reais, mantendo o mesmo formato.\n",
    "\n",
    "**Q: Por que usar implementaÃ§Ã£o manual em vez de DeepXDE?**\n",
    "A: Para fins educacionais e controle total sobre o processo. A implementaÃ§Ã£o manual facilita entendimento e personalizaÃ§Ã£o.\n",
    "\n",
    "### 11.2 Problemas Comuns\n",
    "\n",
    "| Problema | Causa ProvÃ¡vel | SoluÃ§Ã£o |\n",
    "|----------|----------------|---------|\n",
    "| Import Error | DependÃªncias faltando | Execute cÃ©lulas de instalaÃ§Ã£o |\n",
    "| GPU Warning | CUDA nÃ£o configurado | Normal - executarÃ¡ em CPU |\n",
    "| MAE muito alto | HiperparÃ¢metros ruins | Ajustar learning_rate, epochs |\n",
    "| ConvergÃªncia lenta | Loss weights inadequados | Modificar pde_weight, data_weight |\n",
    "| Crash de memÃ³ria | Batch size muito grande | Reduzir BATCH_SIZE |\n",
    "\n",
    "### 11.3 Contato e Suporte\n",
    "\n",
    "Para dÃºvidas adicionais ou problemas nÃ£o cobertos:\n",
    "- Revisar documentaÃ§Ã£o do TensorFlow\n",
    "- Consultar literatura sobre PINNs\n",
    "- Verificar logs de erro detalhados\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ Fim do Notebook - Obrigado pela AtenÃ§Ã£o! ğŸ‰**\n",
    "\n",
    "*Este notebook implementa PINNs para estimativa tÃ©rmica em motores elÃ©tricos seguindo as melhores prÃ¡ticas de engenharia de software e reprodutibilidade cientÃ­fica.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VerificaÃ§Ã£o de integridade dos resultados\n",
    "\n",
    "def verify_experiment_integrity():\n",
    "    \"\"\"\n",
    "    Verifica se todos os experimentos foram executados corretamente.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” VERIFICAÃ‡ÃƒO DE INTEGRIDADE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Verificar estrutura de diretÃ³rios\n",
    "    required_dirs = ['models', 'results', 'plots']\n",
    "    for dir_name in required_dirs:\n",
    "        dir_path = Path(dir_name)\n",
    "        if dir_path.exists():\n",
    "            print(f\"âœ… DiretÃ³rio {dir_name}/ - OK\")\n",
    "        else:\n",
    "            print(f\"âŒ DiretÃ³rio {dir_name}/ - FALTANDO\")\n",
    "    \n",
    "    # Verificar experimentos\n",
    "    experiments = ['E1', 'E2', 'E3']\n",
    "    successful_count = 0\n",
    "    \n",
    "    print(f\"\\\\nğŸ“Š Status dos Experimentos:\")\n",
    "    for exp in experiments:\n",
    "        result = all_results.get(exp)\n",
    "        if result is not None:\n",
    "            metrics = result['metrics']\n",
    "            hypothesis_met = result['config']['hypothesis_met']\n",
    "            \n",
    "            status = \"âœ… SUCESSO\" if hypothesis_met else \"âš ï¸ LIMITADO\"\n",
    "            print(f\"   {exp}: {status} (MAE: {metrics['MAE']:.3f}Â°C)\")\n",
    "            successful_count += 1\n",
    "        else:\n",
    "            print(f\"   {exp}: âŒ FALHOU\")\n",
    "    \n",
    "    # EstatÃ­sticas finais\n",
    "    success_rate = (successful_count / len(experiments)) * 100\n",
    "    \n",
    "    print(f\"\\\\nğŸ“ˆ Resumo Final:\")\n",
    "    print(f\"   â€¢ Experimentos bem-sucedidos: {successful_count}/{len(experiments)}\")\n",
    "    print(f\"   â€¢ Taxa de sucesso: {success_rate:.1f}%\")\n",
    "    \n",
    "    if success_rate == 100:\n",
    "        print(\"   ğŸ‰ PARABÃ‰NS! Todos os experimentos foram executados com sucesso!\")\n",
    "    elif success_rate >= 66.7:\n",
    "        print(\"   âœ… Bom resultado! Maioria dos experimentos bem-sucedida.\")\n",
    "    elif success_rate >= 33.3:\n",
    "        print(\"   âš ï¸ Resultado parcial. Alguns experimentos falharam.\")\n",
    "    else:\n",
    "        print(\"   âŒ Problemas detectados. Revisar configuraÃ§Ã£o e dependÃªncias.\")\n",
    "    \n",
    "    # Verificar arquivos gerados\n",
    "    print(f\"\\\\nğŸ’¾ Arquivos Gerados:\")\n",
    "    file_count = 0\n",
    "    for exp in experiments:\n",
    "        if all_results.get(exp) is not None:\n",
    "            # Verificar modelo\n",
    "            model_file = Path(f\"models/{exp}_model.h5\")\n",
    "            if model_file.exists():\n",
    "                file_count += 1\n",
    "                print(f\"   âœ… {model_file}\")\n",
    "            \n",
    "            # Verificar resultados\n",
    "            results_file = Path(f\"results/{exp}_results.pkl\")\n",
    "            if results_file.exists():\n",
    "                file_count += 1\n",
    "                print(f\"   âœ… {results_file}\")\n",
    "    \n",
    "    print(f\"\\\\n   Total de arquivos gerados: {file_count}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 40)\n",
    "\n",
    "# Executar verificaÃ§Ã£o\n",
    "verify_experiment_integrity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUÃ‡ÃƒO COMPLETA - Descomente para executar com todas as Ã©pocas\n",
    "# âš ï¸ ATENÃ‡ÃƒO: Pode demorar 10-30 minutos dependendo do hardware\n",
    "\n",
    "RUN_FULL_EXPERIMENTS = False  # Mude para True para executar\n",
    "\n",
    "if RUN_FULL_EXPERIMENTS:\n",
    "    print(\"ğŸš€ INICIANDO EXECUÃ‡ÃƒO DOS EXPERIMENTOS COMPLETOS\")\n",
    "    print(\"â±ï¸ AVISO: Isso pode demorar 10-30 minutos...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Armazenar resultados completos\n",
    "    full_results = {}\n",
    "    \n",
    "    # Experimento E1: Dados sintÃ©ticos (completo)\n",
    "    try:\n",
    "        print(\"\\\\nğŸ”¬ Executando E1 completo...\")\n",
    "        results_E1_full = run_experiment(\"E1\", quick_mode=False)\n",
    "        full_results[\"E1\"] = results_E1_full\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro no Experimento E1 completo: {e}\")\n",
    "        full_results[\"E1\"] = None\n",
    "    \n",
    "    # Experimento E2: Ajuste com dados reais (completo)\n",
    "    try:\n",
    "        print(\"\\\\nğŸ”¬ Executando E2 completo...\")\n",
    "        results_E2_full = run_experiment(\"E2\", quick_mode=False)\n",
    "        full_results[\"E2\"] = results_E2_full\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro no Experimento E2 completo: {e}\")\n",
    "        full_results[\"E2\"] = None\n",
    "    \n",
    "    # Experimento E3: InferÃªncia em dados inÃ©ditos (completo)\n",
    "    try:\n",
    "        print(\"\\\\nğŸ”¬ Executando E3 completo...\")\n",
    "        results_E3_full = run_experiment(\"E3\", quick_mode=False)\n",
    "        full_results[\"E3\"] = results_E3_full\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro no Experimento E3 completo: {e}\")\n",
    "        full_results[\"E3\"] = None\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… EXECUÃ‡ÃƒO COMPLETA CONCLUÃDA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Gerar tabela comparativa completa\n",
    "    if any(result is not None for result in full_results.values()):\n",
    "        print(\"\\\\nğŸ“Š TABELA COMPARATIVA - RESULTADOS COMPLETOS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        df_full_results = create_results_summary(full_results)\n",
    "        print(df_full_results.to_string(index=False))\n",
    "        \n",
    "        # Salvar resultados completos\n",
    "        full_results_csv_path = experiment_dir / \"resultados_completos.csv\"\n",
    "        df_full_results.to_csv(full_results_csv_path, index=False)\n",
    "        print(f\"\\\\nğŸ’¾ Resultados completos salvos em: {full_results_csv_path}\")\n",
    "        \n",
    "        # Atualizar variÃ¡vel global\n",
    "        all_results = full_results\n",
    "        \n",
    "else:\n",
    "    print(\"ğŸ“‹ EXECUÃ‡ÃƒO COMPLETA DESABILITADA\")\n",
    "    print(\"   Para executar experimentos completos:\")\n",
    "    print(\"   1. Mude RUN_FULL_EXPERIMENTS = True\")\n",
    "    print(\"   2. Execute esta cÃ©lula novamente\")\n",
    "    print(\"   3. Aguarde 10-30 minutos para conclusÃ£o\")\n",
    "    print(\"\\\\nğŸ’¡ Os resultados do modo rÃ¡pido jÃ¡ fornecem uma boa indicaÃ§Ã£o do desempenho.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
